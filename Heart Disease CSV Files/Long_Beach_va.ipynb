{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "-Gj3J_1rQv3_",
        "outputId": "5a1d466c-6d16-4744-f439-8047ffb4283f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
              "0     63    1   4        10    60    2        1       12      3       11   \n",
              "1     44    1   4         3    19    2        1        8      2       14   \n",
              "2     60    1   4         5    27    2        1       19      3        6   \n",
              "3     55    1   4        11    39    2        1       25      3       10   \n",
              "4     66    1   3        33    22    3        2       53      3        5   \n",
              "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
              "195   54    0   4        41    95    3        1       29      2       14   \n",
              "196   62    1   1         1    30    2        1        1      1        1   \n",
              "197   55    1   4        37    33    3        1        4      2       14   \n",
              "198   58    1   4         1     3    3        2        1      1        1   \n",
              "199   62    1   2        34    56    2        2       47      3       14   \n",
              "\n",
              "     slope  ca  thal  target  \n",
              "0        3   1     1       3  \n",
              "1        1   1     1       1  \n",
              "2        4   1     1       3  \n",
              "3        2   1     1       2  \n",
              "4        3   1     1       1  \n",
              "..     ...  ..   ...     ...  \n",
              "195      1   1     1       2  \n",
              "196      1   1     1       1  \n",
              "197      1   1     3       3  \n",
              "198      1   1     1       1  \n",
              "199      1   1     1       2  \n",
              "\n",
              "[200 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f708b83-3f60-4c0e-a20b-1e618f0eef57\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>60</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>39</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>33</td>\n",
              "      <td>22</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>53</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>41</td>\n",
              "      <td>95</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>37</td>\n",
              "      <td>33</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>47</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 14 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f708b83-3f60-4c0e-a20b-1e618f0eef57')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8f708b83-3f60-4c0e-a20b-1e618f0eef57 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8f708b83-3f60-4c0e-a20b-1e618f0eef57');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c742bf92-f5ab-4aed-bcf0-1699d379c5b7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c742bf92-f5ab-4aed-bcf0-1699d379c5b7')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c742bf92-f5ab-4aed-bcf0-1699d379c5b7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#Import Section\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from mlxtend.classifier import StackingCVClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "import statistics\n",
        "df = pd.read_csv('longbeachva_ds.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df['target'] = np.where(df['target'] > 1, 1, np.where(df['target'] == 1, 0, df['target']))\n",
        "df\n"
      ],
      "metadata": {
        "id": "4sUNk92rRNr-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "591b31e3-c7d2-4aaa-bb48-73a1615e2739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
              "0     63    1   4        10    60    2        1       12      3       11   \n",
              "1     44    1   4         3    19    2        1        8      2       14   \n",
              "2     60    1   4         5    27    2        1       19      3        6   \n",
              "3     55    1   4        11    39    2        1       25      3       10   \n",
              "4     66    1   3        33    22    3        2       53      3        5   \n",
              "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
              "195   54    0   4        41    95    3        1       29      2       14   \n",
              "196   62    1   1         1    30    2        1        1      1        1   \n",
              "197   55    1   4        37    33    3        1        4      2       14   \n",
              "198   58    1   4         1     3    3        2        1      1        1   \n",
              "199   62    1   2        34    56    2        2       47      3       14   \n",
              "\n",
              "     slope  ca  thal  target  \n",
              "0        3   1     1       1  \n",
              "1        1   1     1       0  \n",
              "2        4   1     1       1  \n",
              "3        2   1     1       1  \n",
              "4        3   1     1       0  \n",
              "..     ...  ..   ...     ...  \n",
              "195      1   1     1       1  \n",
              "196      1   1     1       0  \n",
              "197      1   1     3       1  \n",
              "198      1   1     1       0  \n",
              "199      1   1     1       1  \n",
              "\n",
              "[200 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1037d53f-1e0a-4100-a1c4-40be23b829bd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>60</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>39</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>33</td>\n",
              "      <td>22</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>53</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>41</td>\n",
              "      <td>95</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>37</td>\n",
              "      <td>33</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>47</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 14 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1037d53f-1e0a-4100-a1c4-40be23b829bd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1037d53f-1e0a-4100-a1c4-40be23b829bd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1037d53f-1e0a-4100-a1c4-40be23b829bd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f836e40b-877a-4617-ac16-12040c7641b5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f836e40b-877a-4617-ac16-12040c7641b5')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f836e40b-877a-4617-ac16-12040c7641b5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting into features and class label\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X = df.drop('target',axis = 1)\n",
        "y = df['target']\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state = 23)\n",
        "scaler  = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "09kO0rBLTaHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN"
      ],
      "metadata": {
        "id": "VOWoBhFqTV_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "m1 = 'knn classifier'\n",
        "k = 10  # Number of folds\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "total_accuracy = 0\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=9)\n",
        "    knn.fit(X_train_fold, y_train_fold)\n",
        "    knnpred = knn.predict(X_test_fold)\n",
        "    cm = confusion_matrix(y_test_fold, knnpred)\n",
        "    fold_accuracy = accuracy_score(y_test_fold, knnpred) * 100\n",
        "    print('Accuracy for this fold:', fold_accuracy)\n",
        "    total_accuracy += fold_accuracy\n",
        "    print(\"Confusion Matrix for Fold:\")\n",
        "    print(cm)\n",
        "\n",
        "knnaccuracy = total_accuracy / k\n",
        "print(\"Mean Accuracy =\", knnaccuracy)"
      ],
      "metadata": {
        "id": "Xkqi1eAeTUPX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8081a054-cd64-4931-fc39-0569fdc4104a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for this fold: 75.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  3]\n",
            " [ 2 15]]\n",
            "Accuracy for this fold: 75.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  4]\n",
            " [ 1 14]]\n",
            "Accuracy for this fold: 75.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  4]\n",
            " [ 1 15]]\n",
            "Accuracy for this fold: 75.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  3]\n",
            " [ 2 15]]\n",
            "Accuracy for this fold: 85.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  1]\n",
            " [ 2 17]]\n",
            "Accuracy for this fold: 55.00000000000001\n",
            "Confusion Matrix for Fold:\n",
            "[[2 7]\n",
            " [2 9]]\n",
            "Accuracy for this fold: 55.00000000000001\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  9]\n",
            " [ 0 10]]\n",
            "Accuracy for this fold: 65.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  7]\n",
            " [ 0 13]]\n",
            "Accuracy for this fold: 70.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  6]\n",
            " [ 0 14]]\n",
            "Accuracy for this fold: 85.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  3]\n",
            " [ 0 17]]\n",
            "Mean Accuracy = 71.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "PdrCGbobRLZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "m2 = 'lr classifier'\n",
        "\n",
        "\n",
        "k = 10  # Number of folds\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "total_accuracy = 0\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    lr = LogisticRegression()\n",
        "    lr.fit(X_train_fold,y_train_fold)\n",
        "    lrpred = lr.predict(X_test_fold)\n",
        "    cm = confusion_matrix(y_test_fold, lrpred)\n",
        "    fold_accuracy = accuracy_score(y_test_fold, lrpred) * 100\n",
        "    print('Accuracy for this fold:', fold_accuracy)\n",
        "    total_accuracy += fold_accuracy\n",
        "    print(\"Confusion Matrix for Fold:\")\n",
        "    print(cm)\n",
        "\n",
        "lraccuracy = total_accuracy / k\n",
        "print(\"Mean Accuracy =\", lraccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvpDSfMSGAqe",
        "outputId": "1602f8ad-086e-482f-b8eb-28fdec90ea96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for this fold: 85.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  3]\n",
            " [ 0 17]]\n",
            "Accuracy for this fold: 55.00000000000001\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  4]\n",
            " [ 5 10]]\n",
            "Accuracy for this fold: 85.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  3]\n",
            " [ 0 16]]\n",
            "Accuracy for this fold: 75.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  3]\n",
            " [ 2 15]]\n",
            "Accuracy for this fold: 95.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  1]\n",
            " [ 0 19]]\n",
            "Accuracy for this fold: 50.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  9]\n",
            " [ 1 10]]\n",
            "Accuracy for this fold: 50.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0 10]\n",
            " [ 0 10]]\n",
            "Accuracy for this fold: 70.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  6]\n",
            " [ 0 13]]\n",
            "Accuracy for this fold: 75.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  5]\n",
            " [ 0 14]]\n",
            "Accuracy for this fold: 80.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  3]\n",
            " [ 1 16]]\n",
            "Mean Accuracy = 72.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM"
      ],
      "metadata": {
        "id": "BKJkn77KTiTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM\n",
        "m3 = 'svm classifier'\n",
        "\n",
        "k = 10  # Number of folds\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=23)\n",
        "\n",
        "total_accuracy = 0\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    Svm = SVC(kernel = 'linear',C=2,probability=True)\n",
        "    Svm.fit(X_train_fold,y_train_fold)\n",
        "    Svmpred = Svm.predict(X_test_fold)\n",
        "    cm = confusion_matrix(y_test_fold, Svmpred)\n",
        "    fold_accuracy = accuracy_score(y_test_fold, Svmpred) * 100\n",
        "    print('Accuracy for this fold:', fold_accuracy)\n",
        "    total_accuracy += fold_accuracy\n",
        "    print(\"Confusion Matrix for Fold:\")\n",
        "    print(cm)\n",
        "\n",
        "svmaccuracy = total_accuracy / k\n",
        "print(\"Mean Accuracy =\", svmaccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmoCazr5TnAK",
        "outputId": "a5a1ec29-5f7c-4286-e302-db9b463261a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for this fold: 65.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 2  3]\n",
            " [ 4 11]]\n",
            "Accuracy for this fold: 70.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  6]\n",
            " [ 0 14]]\n",
            "Accuracy for this fold: 70.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  5]\n",
            " [ 1 14]]\n",
            "Accuracy for this fold: 75.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  3]\n",
            " [ 2 15]]\n",
            "Accuracy for this fold: 75.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  4]\n",
            " [ 1 15]]\n",
            "Accuracy for this fold: 50.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  9]\n",
            " [ 1 10]]\n",
            "Accuracy for this fold: 75.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  5]\n",
            " [ 0 15]]\n",
            "Accuracy for this fold: 70.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  6]\n",
            " [ 0 14]]\n",
            "Accuracy for this fold: 80.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  4]\n",
            " [ 0 16]]\n",
            "Accuracy for this fold: 75.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  4]\n",
            " [ 1 15]]\n",
            "Mean Accuracy = 70.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gaussian NB"
      ],
      "metadata": {
        "id": "KPC145a2Tvj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GaussianNB\n",
        "\n",
        "m5 = 'gaussian nb'\n",
        "k = 10  # Number of folds\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=23)\n",
        "\n",
        "total_accuracy = 0\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    nb = GaussianNB()\n",
        "    nb.fit(X_train_fold,y_train_fold)\n",
        "    nbpred = nb.predict(X_test_fold)\n",
        "    cm = confusion_matrix(y_test_fold, nbpred)\n",
        "    fold_accuracy = accuracy_score(y_test_fold, nbpred) * 100\n",
        "    print('Accuracy for this fold:', fold_accuracy)\n",
        "    total_accuracy += fold_accuracy\n",
        "    print(\"Confusion Matrix for Fold:\")\n",
        "    print(cm)\n",
        "\n",
        "nbaccuracy = total_accuracy / k\n",
        "print(\"Mean Accuracy =\", nbaccuracy)"
      ],
      "metadata": {
        "id": "7W8n1r7mTyhK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d17ee1e8-0005-4b55-acdd-fcb087fdeb71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for this fold: 80.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 2  3]\n",
            " [ 1 14]]\n",
            "Accuracy for this fold: 80.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 2  4]\n",
            " [ 0 14]]\n",
            "Accuracy for this fold: 75.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  4]\n",
            " [ 1 14]]\n",
            "Accuracy for this fold: 70.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  2]\n",
            " [ 4 13]]\n",
            "Accuracy for this fold: 80.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  3]\n",
            " [ 1 15]]\n",
            "Accuracy for this fold: 65.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 3  6]\n",
            " [ 1 10]]\n",
            "Accuracy for this fold: 75.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  4]\n",
            " [ 1 14]]\n",
            "Accuracy for this fold: 65.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  5]\n",
            " [ 2 12]]\n",
            "Accuracy for this fold: 85.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  3]\n",
            " [ 0 16]]\n",
            "Accuracy for this fold: 20.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 3  1]\n",
            " [15  1]]\n",
            "Mean Accuracy = 69.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree"
      ],
      "metadata": {
        "id": "0JSuqzPNT1BJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DT\n",
        "m4 = 'decision tree'\n",
        "\n",
        "k = 10  # Number of folds\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=23)\n",
        "\n",
        "total_accuracy = 0\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    dt = DecisionTreeClassifier(criterion='entropy',random_state = 0,max_depth=6)\n",
        "    dt.fit(X_train_fold,y_train_fold)\n",
        "    dtpred = dt.predict(X_test_fold)\n",
        "    cm = confusion_matrix(y_test_fold, dtpred)\n",
        "    fold_accuracy = accuracy_score(y_test_fold, dtpred) * 100\n",
        "    print('Accuracy for this fold:', fold_accuracy)\n",
        "    total_accuracy += fold_accuracy\n",
        "    print(\"Confusion Matrix for Fold:\")\n",
        "    print(cm)\n",
        "\n",
        "dtaccuracy = total_accuracy / k\n",
        "print(\"Mean Accuracy =\", dtaccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI-eV6R0T_Vg",
        "outputId": "ef0704ee-0e57-4230-d9da-a2161eb68d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for this fold: 65.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  4]\n",
            " [ 3 12]]\n",
            "Accuracy for this fold: 75.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 2  4]\n",
            " [ 1 13]]\n",
            "Accuracy for this fold: 50.0\n",
            "Confusion Matrix for Fold:\n",
            "[[1 4]\n",
            " [6 9]]\n",
            "Accuracy for this fold: 55.00000000000001\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  3]\n",
            " [ 6 11]]\n",
            "Accuracy for this fold: 70.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  3]\n",
            " [ 3 13]]\n",
            "Accuracy for this fold: 55.00000000000001\n",
            "Confusion Matrix for Fold:\n",
            "[[2 7]\n",
            " [2 9]]\n",
            "Accuracy for this fold: 65.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  5]\n",
            " [ 2 13]]\n",
            "Accuracy for this fold: 70.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  6]\n",
            " [ 0 14]]\n",
            "Accuracy for this fold: 80.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 2  2]\n",
            " [ 2 14]]\n",
            "Accuracy for this fold: 75.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  3]\n",
            " [ 2 14]]\n",
            "Mean Accuracy = 66.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QDA"
      ],
      "metadata": {
        "id": "abNGvcQtRa3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "m6 = 'qda classifier'\n",
        "\n",
        "k = 10  # Number of folds\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=23)\n",
        "\n",
        "total_accuracy = 0\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    qda = QuadraticDiscriminantAnalysis()\n",
        "    qda.fit(X_train_fold, y_train_fold)\n",
        "    qdapred = qda.predict(X_test_fold)\n",
        "    cm = confusion_matrix(y_test_fold, qdapred)\n",
        "    fold_accuracy = accuracy_score(y_test_fold, qdapred) * 100\n",
        "    print('Accuracy for this fold:', fold_accuracy)\n",
        "    total_accuracy += fold_accuracy\n",
        "    print(\"Confusion Matrix for Fold:\")\n",
        "    print(cm)\n",
        "\n",
        "qdaaccuracy = total_accuracy / k\n",
        "print(\"Mean Accuracy =\", qdaaccuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwPZ1uJQGTBF",
        "outputId": "dd5f6747-47a3-4463-e31f-663ec5d5152c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for this fold: 75.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 2  3]\n",
            " [ 2 13]]\n",
            "Accuracy for this fold: 80.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 2  4]\n",
            " [ 0 14]]\n",
            "Accuracy for this fold: 75.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  5]\n",
            " [ 0 15]]\n",
            "Accuracy for this fold: 75.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  2]\n",
            " [ 3 14]]\n",
            "Accuracy for this fold: 70.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  4]\n",
            " [ 2 14]]\n",
            "Accuracy for this fold: 70.0\n",
            "Confusion Matrix for Fold:\n",
            "[[5 4]\n",
            " [2 9]]\n",
            "Accuracy for this fold: 75.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  4]\n",
            " [ 1 14]]\n",
            "Accuracy for this fold: 70.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 2  4]\n",
            " [ 2 12]]\n",
            "Accuracy for this fold: 70.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  3]\n",
            " [ 3 13]]\n",
            "Accuracy for this fold: 20.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 4  0]\n",
            " [16  0]]\n",
            "Mean Accuracy = 68.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest (BAGGING)"
      ],
      "metadata": {
        "id": "PqPbfPQPRcTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "m7 = 'rf classifier'\n",
        "k = 10  # Number of folds\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "total_accuracy = 0\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    rf = RandomForestClassifier(n_estimators=5, random_state=23,max_depth=4)\n",
        "    rf.fit(X_train_fold, y_train_fold)\n",
        "    rfpred = rf.predict(X_test_fold)\n",
        "    cm = confusion_matrix(y_test_fold, rfpred)\n",
        "    fold_accuracy = accuracy_score(y_test_fold, rfpred) * 100\n",
        "    print('Accuracy for this fold:', fold_accuracy)\n",
        "    total_accuracy += fold_accuracy\n",
        "    print(\"Confusion Matrix for Fold:\")\n",
        "    print(cm)\n",
        "\n",
        "rfaccuracy = total_accuracy / k\n",
        "print(\"Mean Accuracy =\", rfaccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjbP3Aw4GVRd",
        "outputId": "a04ae481-4b67-4154-a5e9-ce2bbb0af0c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for this fold: 85.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  2]\n",
            " [ 1 16]]\n",
            "Accuracy for this fold: 65.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  5]\n",
            " [ 2 13]]\n",
            "Accuracy for this fold: 75.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  3]\n",
            " [ 2 14]]\n",
            "Accuracy for this fold: 80.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  3]\n",
            " [ 1 16]]\n",
            "Accuracy for this fold: 85.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  1]\n",
            " [ 2 17]]\n",
            "Accuracy for this fold: 60.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  8]\n",
            " [ 0 11]]\n",
            "Accuracy for this fold: 55.00000000000001\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  9]\n",
            " [ 0 10]]\n",
            "Accuracy for this fold: 75.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 3  4]\n",
            " [ 1 12]]\n",
            "Accuracy for this fold: 70.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  6]\n",
            " [ 0 14]]\n",
            "Accuracy for this fold: 85.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  2]\n",
            " [ 1 16]]\n",
            "Mean Accuracy = 73.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADABOOST (BOOSTING)"
      ],
      "metadata": {
        "id": "xJ6sfW_8RfFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m8 = 'adaboost classifier'\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "k = 10\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=23)\n",
        "\n",
        "total_accuracy = 0\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    base_classifier = DecisionTreeClassifier(max_depth=6)\n",
        "    adaboost_classifier = AdaBoostClassifier(base_classifier, n_estimators=20, random_state=23)\n",
        "    adaboost_classifier.fit(X_train_fold, y_train_fold)\n",
        "    boostpred = adaboost_classifier.predict(X_test_fold)\n",
        "    cm = confusion_matrix(y_test_fold, boostpred)\n",
        "    fold_accuracy = accuracy_score(y_test_fold, boostpred) * 100\n",
        "    print('Accuracy for this fold:', fold_accuracy)\n",
        "    total_accuracy += fold_accuracy\n",
        "    print(\"Confusion Matrix for Fold:\")\n",
        "    print(cm)\n",
        "\n",
        "boostaccuracy = total_accuracy / k\n",
        "print(\"Mean Accuracy =\", boostaccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3IxuMEpGZZh",
        "outputId": "9f686b22-0cfa-491e-a37c-205ba54ee61b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for this fold: 75.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 2  3]\n",
            " [ 2 13]]\n",
            "Accuracy for this fold: 70.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  5]\n",
            " [ 1 13]]\n",
            "Accuracy for this fold: 65.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  4]\n",
            " [ 3 12]]\n",
            "Accuracy for this fold: 60.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  3]\n",
            " [ 5 12]]\n",
            "Accuracy for this fold: 65.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  4]\n",
            " [ 3 13]]\n",
            "Accuracy for this fold: 75.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 4  5]\n",
            " [ 0 11]]\n",
            "Accuracy for this fold: 65.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 1  4]\n",
            " [ 3 12]]\n",
            "Accuracy for this fold: 55.00000000000001\n",
            "Confusion Matrix for Fold:\n",
            "[[ 0  6]\n",
            " [ 3 11]]\n",
            "Accuracy for this fold: 80.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 3  1]\n",
            " [ 3 13]]\n",
            "Accuracy for this fold: 85.0\n",
            "Confusion Matrix for Fold:\n",
            "[[ 2  2]\n",
            " [ 1 15]]\n",
            "Mean Accuracy = 69.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DeepLearning Model"
      ],
      "metadata": {
        "id": "aoZCh6QnUAw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxSFJ_CMUFss",
        "outputId": "12ffa779-3c91-427d-f4b0-08e7a2b30124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.3/612.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.22.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "input_layer = Input(shape=(X_train.shape[1],))\n",
        "d1 = Dense(units=100, activation='relu')(input_layer)\n",
        "d2 = Dense(units=100, activation='relu')(d1)\n",
        "d3 = Dense(units=100, activation='relu')(d2)\n",
        "d4 = Dense(units=100, activation='relu')(d3)\n",
        "# d5 = Dense(units=100, activation='relu')(d4)\n",
        "# d6 = Dense(units=100, activation='relu')(d5)\n",
        "# d7 = Dense(units=100, activation='relu')(d6)\n",
        "# d8 = Dense(units=100, activation='relu')(d7)\n",
        "# d9 = Dense(units=100, activation='relu')(d8)\n",
        "output_layer = Dense(units=1, activation='sigmoid')(d4)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model with metrics and optimizer\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.Recall(name=\"Sensitivity\"),\n",
        "             tf.keras.metrics.SpecificityAtSensitivity(0.5, name=\"Specificity\"),\n",
        "             tfa.metrics.F1Score(num_classes=1, threshold=0.5)],\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(x=X_train, y=y_train, batch_size=2, epochs=120)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy, sensitivity, specificity, f1_score = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Sensitivity (Recall): {sensitivity:.2f}\")\n",
        "print(f\"Specificity: {specificity:.2f}\")\n",
        "print(\"x=\" + str(list(map('{:.2f}%'.format,f1_score))))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3C_2m1zUKLB",
        "outputId": "b3893698-a8bc-4ba1-fcaa-a13f0f7f7c1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "80/80 [==============================] - 2s 4ms/step - loss: 0.6956 - accuracy: 0.5437 - Sensitivity: 0.5250 - Specificity: 0.5750 - f1_score: 0.6332\n",
            "Epoch 2/120\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.6375 - Sensitivity: 0.7083 - Specificity: 0.5750 - f1_score: 0.7456\n",
            "Epoch 3/120\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.6762 - accuracy: 0.6750 - Sensitivity: 0.8333 - Specificity: 0.6000 - f1_score: 0.7937\n",
            "Epoch 4/120\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.6679 - accuracy: 0.7063 - Sensitivity: 0.9250 - Specificity: 0.5750 - f1_score: 0.8253\n",
            "Epoch 5/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.6597 - accuracy: 0.7375 - Sensitivity: 0.9750 - Specificity: 0.6000 - f1_score: 0.8478\n",
            "Epoch 6/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.6520 - accuracy: 0.7500 - Sensitivity: 0.9917 - Specificity: 0.6250 - f1_score: 0.8561\n",
            "Epoch 7/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.7500 - Sensitivity: 0.9917 - Specificity: 0.6250 - f1_score: 0.8561\n",
            "Epoch 8/120\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6376 - accuracy: 0.7437 - Sensitivity: 0.9917 - Specificity: 0.6250 - f1_score: 0.8530\n",
            "Epoch 9/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.6311 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.6500 - f1_score: 0.8571\n",
            "Epoch 10/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.6500 - f1_score: 0.8571\n",
            "Epoch 11/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.6188 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.6500 - f1_score: 0.8571\n",
            "Epoch 12/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.6130 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.6500 - f1_score: 0.8571\n",
            "Epoch 13/120\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6071 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.6500 - f1_score: 0.8571\n",
            "Epoch 14/120\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6014 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.6750 - f1_score: 0.8571\n",
            "Epoch 15/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.6500 - f1_score: 0.8571\n",
            "Epoch 16/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5903 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.7250 - f1_score: 0.8571\n",
            "Epoch 17/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.7250 - f1_score: 0.8571\n",
            "Epoch 18/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.7500 - f1_score: 0.8571\n",
            "Epoch 19/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5753 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.7500 - f1_score: 0.8571\n",
            "Epoch 20/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.7250 - f1_score: 0.8571\n",
            "Epoch 21/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.7500 - f1_score: 0.8571\n",
            "Epoch 22/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.7750 - f1_score: 0.8571\n",
            "Epoch 23/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.7750 - f1_score: 0.8571\n",
            "Epoch 24/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.7500 - f1_score: 0.8571\n",
            "Epoch 25/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.7750 - f1_score: 0.8571\n",
            "Epoch 26/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.7750 - f1_score: 0.8571\n",
            "Epoch 27/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5419 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.7750 - f1_score: 0.8571\n",
            "Epoch 28/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.7500 - f1_score: 0.8571\n",
            "Epoch 29/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.8000 - f1_score: 0.8571\n",
            "Epoch 30/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5322 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.8000 - f1_score: 0.8571\n",
            "Epoch 31/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.7500 - f1_score: 0.8571\n",
            "Epoch 32/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.7750 - f1_score: 0.8571\n",
            "Epoch 33/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.8500 - f1_score: 0.8571\n",
            "Epoch 34/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.9000 - f1_score: 0.8571\n",
            "Epoch 35/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.8750 - f1_score: 0.8571\n",
            "Epoch 36/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.9000 - f1_score: 0.8571\n",
            "Epoch 37/120\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.9000 - f1_score: 0.8571\n",
            "Epoch 38/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.9000 - f1_score: 0.8571\n",
            "Epoch 39/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.9000 - f1_score: 0.8571\n",
            "Epoch 40/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.9000 - f1_score: 0.8571\n",
            "Epoch 41/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.9000 - f1_score: 0.8571\n",
            "Epoch 42/120\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.9250 - f1_score: 0.8571\n",
            "Epoch 43/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.9000 - f1_score: 0.8571\n",
            "Epoch 44/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.9250 - f1_score: 0.8571\n",
            "Epoch 45/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.9250 - f1_score: 0.8571\n",
            "Epoch 46/120\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.9250 - f1_score: 0.8571\n",
            "Epoch 47/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.9250 - f1_score: 0.8571\n",
            "Epoch 48/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.9250 - f1_score: 0.8571\n",
            "Epoch 49/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.9000 - f1_score: 0.8571\n",
            "Epoch 50/120\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.9250 - f1_score: 0.8571\n",
            "Epoch 51/120\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.9250 - f1_score: 0.8571\n",
            "Epoch 52/120\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7500 - Sensitivity: 1.0000 - Specificity: 0.9250 - f1_score: 0.8571\n",
            "Epoch 53/120\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7563 - Sensitivity: 1.0000 - Specificity: 0.9250 - f1_score: 0.8602\n",
            "Epoch 54/120\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7563 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8602\n",
            "Epoch 55/120\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7563 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8602\n",
            "Epoch 56/120\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7563 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8602\n",
            "Epoch 57/120\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7625 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8633\n",
            "Epoch 58/120\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7625 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8633\n",
            "Epoch 59/120\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7625 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8633\n",
            "Epoch 60/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7688 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8664\n",
            "Epoch 61/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7688 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8664\n",
            "Epoch 62/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7688 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8664\n",
            "Epoch 63/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7750 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8696\n",
            "Epoch 64/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7812 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8727\n",
            "Epoch 65/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7812 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8727\n",
            "Epoch 66/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7875 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8759\n",
            "Epoch 67/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7875 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8759\n",
            "Epoch 68/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7875 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8759\n",
            "Epoch 69/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7875 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8759\n",
            "Epoch 70/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7875 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8759\n",
            "Epoch 71/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7875 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8759\n",
            "Epoch 72/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7937 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8791\n",
            "Epoch 73/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7937 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8791\n",
            "Epoch 74/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7937 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8791\n",
            "Epoch 75/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7937 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8791\n",
            "Epoch 76/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7937 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8791\n",
            "Epoch 77/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7937 - Sensitivity: 1.0000 - Specificity: 0.9500 - f1_score: 0.8791\n",
            "Epoch 78/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7937 - Sensitivity: 0.9917 - Specificity: 0.9500 - f1_score: 0.8782\n",
            "Epoch 79/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8000 - Sensitivity: 0.9917 - Specificity: 0.9500 - f1_score: 0.8815\n",
            "Epoch 80/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.8125 - Sensitivity: 0.9917 - Specificity: 0.9500 - f1_score: 0.8881\n",
            "Epoch 81/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8125 - Sensitivity: 0.9917 - Specificity: 0.9500 - f1_score: 0.8881\n",
            "Epoch 82/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8125 - Sensitivity: 0.9917 - Specificity: 0.9500 - f1_score: 0.8881\n",
            "Epoch 83/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.8125 - Sensitivity: 0.9917 - Specificity: 0.9500 - f1_score: 0.8881\n",
            "Epoch 84/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8188 - Sensitivity: 0.9917 - Specificity: 0.9500 - f1_score: 0.8914\n",
            "Epoch 85/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.8250 - Sensitivity: 0.9917 - Specificity: 0.9500 - f1_score: 0.8947\n",
            "Epoch 86/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4128 - accuracy: 0.8250 - Sensitivity: 0.9917 - Specificity: 0.9500 - f1_score: 0.8947\n",
            "Epoch 87/120\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8250 - Sensitivity: 0.9917 - Specificity: 0.9500 - f1_score: 0.8947\n",
            "Epoch 88/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8250 - Sensitivity: 0.9917 - Specificity: 0.9500 - f1_score: 0.8947\n",
            "Epoch 89/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.8250 - Sensitivity: 0.9917 - Specificity: 0.9500 - f1_score: 0.8947\n",
            "Epoch 90/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8250 - Sensitivity: 0.9917 - Specificity: 0.9500 - f1_score: 0.8947\n",
            "Epoch 91/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.8250 - Sensitivity: 0.9917 - Specificity: 0.9500 - f1_score: 0.8947\n",
            "Epoch 92/120\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8250 - Sensitivity: 0.9917 - Specificity: 0.9500 - f1_score: 0.8947\n",
            "Epoch 93/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.8250 - Sensitivity: 0.9917 - Specificity: 0.9750 - f1_score: 0.8947\n",
            "Epoch 94/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.8250 - Sensitivity: 0.9917 - Specificity: 0.9750 - f1_score: 0.8947\n",
            "Epoch 95/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.8250 - Sensitivity: 0.9917 - Specificity: 0.9750 - f1_score: 0.8947\n",
            "Epoch 96/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.3993 - accuracy: 0.8250 - Sensitivity: 0.9917 - Specificity: 0.9750 - f1_score: 0.8947\n",
            "Epoch 97/120\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8313 - Sensitivity: 0.9917 - Specificity: 0.9750 - f1_score: 0.8981\n",
            "Epoch 98/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.3964 - accuracy: 0.8313 - Sensitivity: 0.9917 - Specificity: 0.9750 - f1_score: 0.8981\n",
            "Epoch 99/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.3951 - accuracy: 0.8313 - Sensitivity: 0.9917 - Specificity: 0.9750 - f1_score: 0.8981\n",
            "Epoch 100/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.8313 - Sensitivity: 0.9917 - Specificity: 0.9750 - f1_score: 0.8981\n",
            "Epoch 101/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.3927 - accuracy: 0.8375 - Sensitivity: 0.9917 - Specificity: 0.9750 - f1_score: 0.9015\n",
            "Epoch 102/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.3912 - accuracy: 0.8375 - Sensitivity: 0.9917 - Specificity: 0.9750 - f1_score: 0.9015\n",
            "Epoch 103/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.3901 - accuracy: 0.8375 - Sensitivity: 0.9917 - Specificity: 0.9750 - f1_score: 0.9015\n",
            "Epoch 104/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.8313 - Sensitivity: 0.9833 - Specificity: 0.9750 - f1_score: 0.8973\n",
            "Epoch 105/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.3875 - accuracy: 0.8313 - Sensitivity: 0.9833 - Specificity: 0.9750 - f1_score: 0.8973\n",
            "Epoch 106/120\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.3863 - accuracy: 0.8313 - Sensitivity: 0.9833 - Specificity: 0.9750 - f1_score: 0.8973\n",
            "Epoch 107/120\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.3852 - accuracy: 0.8313 - Sensitivity: 0.9833 - Specificity: 0.9750 - f1_score: 0.8973\n",
            "Epoch 108/120\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.3840 - accuracy: 0.8313 - Sensitivity: 0.9833 - Specificity: 0.9750 - f1_score: 0.8973\n",
            "Epoch 109/120\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.3827 - accuracy: 0.8375 - Sensitivity: 0.9833 - Specificity: 0.9750 - f1_score: 0.9008\n",
            "Epoch 110/120\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.3818 - accuracy: 0.8375 - Sensitivity: 0.9833 - Specificity: 0.9750 - f1_score: 0.9008\n",
            "Epoch 111/120\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.3808 - accuracy: 0.8375 - Sensitivity: 0.9833 - Specificity: 0.9750 - f1_score: 0.9008\n",
            "Epoch 112/120\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.3796 - accuracy: 0.8375 - Sensitivity: 0.9833 - Specificity: 0.9750 - f1_score: 0.9008\n",
            "Epoch 113/120\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.3783 - accuracy: 0.8375 - Sensitivity: 0.9833 - Specificity: 0.9750 - f1_score: 0.9008\n",
            "Epoch 114/120\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.3770 - accuracy: 0.8375 - Sensitivity: 0.9833 - Specificity: 0.9750 - f1_score: 0.9008\n",
            "Epoch 115/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.3758 - accuracy: 0.8375 - Sensitivity: 0.9833 - Specificity: 0.9750 - f1_score: 0.9008\n",
            "Epoch 116/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8375 - Sensitivity: 0.9833 - Specificity: 0.9750 - f1_score: 0.9008\n",
            "Epoch 117/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.3736 - accuracy: 0.8375 - Sensitivity: 0.9833 - Specificity: 0.9750 - f1_score: 0.9008\n",
            "Epoch 118/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.3724 - accuracy: 0.8375 - Sensitivity: 0.9833 - Specificity: 0.9750 - f1_score: 0.9008\n",
            "Epoch 119/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8375 - Sensitivity: 0.9833 - Specificity: 0.9750 - f1_score: 0.9008\n",
            "Epoch 120/120\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.3701 - accuracy: 0.8375 - Sensitivity: 0.9833 - Specificity: 0.9750 - f1_score: 0.9008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x794e8ce14af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5942 - accuracy: 0.7500 - Sensitivity: 0.9655 - Specificity: 0.8182 - f1_score: 0.8485\n",
            "Test Accuracy: 75.00%\n",
            "Sensitivity (Recall): 0.97\n",
            "Specificity: 0.82\n",
            "x=['0.85%']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"IN LONG BEACH VA DATASET\")\n",
        "model_names = ['Logistic Regression', 'Naive Bayes', 'Random Forest','adaboost classifier', 'K-Nearest Neighbour', 'Decision Tree', 'Support Vector Machine','Deep Learning Model ']\n",
        "accuracy_scores = [lraccuracy,nbaccuracy,rfaccuracy,boostaccuracy,knnaccuracy,dtaccuracy,svmaccuracy,test_accuracy*100]\n",
        "model_ev = pd.DataFrame({'Model': model_names, 'Accuracy': accuracy_scores})\n",
        "model_ev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "C-wn4wPUUNTf",
        "outputId": "cf5f6107-0c8b-4789-b844-cb0bc9bb618c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IN LONG BEACH VA DATASET\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Model  Accuracy\n",
              "0     Logistic Regression      72.0\n",
              "1             Naive Bayes      69.5\n",
              "2           Random Forest      73.5\n",
              "3     adaboost classifier      69.5\n",
              "4     K-Nearest Neighbour      71.5\n",
              "5           Decision Tree      66.0\n",
              "6  Support Vector Machine      70.5\n",
              "7    Deep Learning Model       75.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9267679e-3950-4d1d-be61-917e8088d6c5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>72.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>69.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>73.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>adaboost classifier</td>\n",
              "      <td>69.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>K-Nearest Neighbour</td>\n",
              "      <td>71.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>66.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Support Vector Machine</td>\n",
              "      <td>70.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Deep Learning Model</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9267679e-3950-4d1d-be61-917e8088d6c5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9267679e-3950-4d1d-be61-917e8088d6c5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9267679e-3950-4d1d-be61-917e8088d6c5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-075a5cc1-e1e0-448b-8958-19baaaa09015\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-075a5cc1-e1e0-448b-8958-19baaaa09015')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-075a5cc1-e1e0-448b-8958-19baaaa09015 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "colors = ['red', 'orange', 'yellow', 'green', 'blue', 'gold', 'orange', ]\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.title(\"Barchart Accuracy of Different ML Models\")\n",
        "plt.xlabel(\"Algorithms\")\n",
        "plt.ylabel(\"% Accuracy\")\n",
        "plt.bar(model_ev ['Model'], model_ev['Accuracy'], color = colors)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "23ysr0m6Uqmw",
        "outputId": "45059e7a-02f7-4753-c061-6f91d9655bb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABlAAAAK9CAYAAABb4SGbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACDOElEQVR4nOzdd5hU5dk/8HuXskvbpUhVml1JbNiwAYoiNlSMDRV7oqhRLBFjRMGIJdb3RY0RwVdFE8CeYMOIxoKo2BsoClEBSyhiKMLz+8OL+TlnAXdlYRA/n+uaC+Y5z5xznzPPzJyZ755zilJKKQAAAAAAAMgpLnQBAAAAAAAAaxoBCgAAAAAAQIYABQAAAAAAIEOAAgAAAAAAkCFAAQAAAAAAyBCgAAAAAAAAZAhQAAAAAAAAMgQoAAAAAAAAGQIUAAAAAACADAEKAABrpeHDh0dRUVG89NJLhS6FNcBVV10V66+/ftSoUSO22mqrap13ly5dokuXLnltM2bMiEMOOSSaNGkSRUVFcd1110VExKRJk2KvvfaK8vLyKCoqivvvv79aa2H1aNeuXRx77LE/6rFFRUVx8cUXV2s9AACsGgIUAABW2tKw4vu3Zs2aRdeuXWPMmDGFLm+1uPHGG2P48OFVftysWbOitLQ0ioqK4p133qn+wojHHnsszjvvvNh5551j2LBhcdllly2377HHHps3juvXrx/rr79+HHLIITF69OhYsmRJpZZ51llnxaOPPhr9+/ePO+64I/bee++IiOjTp0+88cYb8cc//jHuuOOO2HbbbatlHVeFyy67rNIBz0cffZTbZpdeeuky+/Tu3Tu3Tb+vS5cu8Ytf/KLK9T311FO5Zd55553L7LPzzjtHUVHRj5o/AADULHQBAACsPQYOHBjt27ePlFLMmDEjhg8fHvvss0889NBDsd9++xW6vFXqxhtvjHXWWafKf5U+cuTIKCoqihYtWsRdd9213B+f+fGefPLJKC4ujqFDh0bt2rV/sH9JSUnceuutERHx3//+Nz7++ON46KGH4pBDDokuXbrEAw88EGVlZbn+jz322DKX2bNnzzjnnHNybf/973/j+eefj9///vdx2mmnVcOarVqXXXZZHHLIIXHggQdW+jGlpaVx9913x4UXXpjXPm/evHjggQeitLS0mqv8bpkjRoyIo446Kq/9o48+iueee26VLBMAgJ8HR6AAAFBtevToEUcddVQcffTRcc4558QzzzwTtWrVirvvvrta5r9kyZKYP39+tcyrunzzzTcr9fg777wz9tlnnzjiiCNixIgR1VRV9Zs/f36lj75Y08ycOTPq1KlTqfAkIqJmzZpx1FFHxVFHHRUnnXRSXHrppfHaa6/F4MGD46mnnoqTTjopr3/t2rUrzHvmzJnRsGHDvLbPP/88IqJC+8pY056XffbZJ95+++147bXX8tofeOCBWLhwYey5556rZJmPP/54fPHFF3ntI0aMiObNm6/RR/kAALBmE6AAALDKNGzYMOrUqRM1a+Yf+PynP/0pdtppp2jSpEnUqVMnOnbsGKNGjarw+KKiojjttNPirrvuig4dOkRJSUk88sgjERHxySefxAknnBCtWrWKkpKSaN++fZxyyimxcOHCvHksWLAg+vXrF02bNo169erFQQcdlPshe6kHHngg9t1339y8Nthggxg0aFAsXrw4r9/SUw29/PLLsdtuu0XdunXjggsuiHbt2sVbb70V48aNy51SKHtNjGWZOnVqPPPMM3H44YfH4YcfHlOmTInnnntumX3vvPPO2H777aNu3brRqFGj2G233Soc+TBmzJjo3LlzNGjQIMrKymK77bbLC2WWd92G7DU8lp4a6Z577okLL7ww1l133ahbt27MmTMnvvrqqzjnnHPil7/8ZdSvXz/KysqiR48eFX4wj/jux/2LL744Nt544ygtLY2WLVvGwQcfHB988EGklKJdu3bRs2fPZT6uvLw8fv3rX69w+3377bcxaNCg2GCDDaKkpCTatWsXF1xwQSxYsCDXp6ioKIYNGxbz5s3LPTc/5lRrERHnn39+7LXXXjFy5Mh4//33c+3f335LT2eXUoohQ4bklnnxxRdH27ZtIyLi3HPPjaKiomjXrl1uHp988kkcf/zx0bx58ygpKYkOHTrEbbfdlrf8FT0vERHjx4+PvffeO8rLy6Nu3brRuXPnePbZZ/PmcfHFF0dRUVFMnjw5jj322GjYsGGUl5fHcccdlxcGFhUVxbx58+L222/PrUNljq7q1KlTtG/fvkIYeNddd8Xee+8djRs3/sF5VFXPnj2jpKQkRo4cmdc+YsSIOPTQQ6NGjRoVHlOZsRMRkVKKSy+9NNZbb72oW7dudO3aNd56661l1jFr1qw488wzo3Xr1lFSUhIbbrhhXHHFFT8YcM2dOzfOPPPMaNeuXZSUlESzZs1izz33jFdeeaWKWwIAgOrmFF4AAFSb2bNnxxdffBEppZg5c2b8z//8T3z99dcVTq1z/fXXxwEHHBC9e/eOhQsXxj333BO/+tWv4uGHH4599903r++TTz4Zf/vb3+K0006LddZZJ9q1axeffvppbL/99jFr1qw4+eSTY9NNN41PPvkkRo0aFd98803e0QCnn356NGrUKAYMGBAfffRRXHfddXHaaafFX//611yf4cOHR/369aNfv35Rv379ePLJJ+Oiiy6KOXPmxFVXXZVXz5dffhk9evSIww8/PI466qho3rx5dOnSJU4//fSoX79+/P73v4+IiObNm//g9rr77rujXr16sd9++0WdOnVigw02iLvuuit22mmnvH6XXHJJXHzxxbHTTjvFwIEDo3bt2jF+/Ph48sknY6+99sqtw/HHHx8dOnSI/v37R8OGDWPixInxyCOPxJFHHlmJZ6+iQYMGRe3ateOcc86JBQsWRO3atePtt9+O+++/P371q19F+/btY8aMGfHnP/85OnfuHG+//Xa0atUqIiIWL14c++23X4wdOzYOP/zw+O1vfxtz586Nxx9/PN58883YYIMN4qijjoorr7wyvvrqq7wf1h966KGYM2dOhXGTdeKJJ8btt98ehxxySJx99tkxfvz4GDx4cLzzzjtx3333RUTEHXfcEbfccku8+OKLudNyZbdvVRx99NHx2GOPxeOPPx4bb7xxhem77bZb3HHHHXH00UfHnnvuGcccc0xERGyxxRbRsGHDOOuss+KII46IffbZJ3ctkBkzZsSOO+6YCwybNm0aY8aMiRNOOCHmzJkTZ555Zt4ylvW8PPnkk9GjR4/o2LFjDBgwIIqLi2PYsGGx++67xzPPPBPbb7993jwOPfTQaN++fQwePDheeeWVuPXWW6NZs2ZxxRVX5LbbiSeeGNtvv32cfPLJERGxwQYbVGobHXHEEXHnnXfG5ZdfHkVFRfHFF1/EY489FnfccUcuAK1OdevWjZ49e8bdd98dp5xySkREvPbaa/HWW2/FrbfeGq+//nqFx1Rm7EREXHTRRXHppZfGPvvsE/vss0+88sorsddee1UIar/55pvo3LlzfPLJJ/HrX/862rRpE88991z0798/Pvvss7juuuuWW/9vfvObGDVqVJx22mmx+eabx5dffhn/+te/4p133oltttmmejYSAAA/TgIAgJU0bNiwFBEVbiUlJWn48OEV+n/zzTd59xcuXJh+8YtfpN133z2vPSJScXFxeuutt/LajznmmFRcXJwmTJhQYd5LlizJq6lbt265tpRSOuuss1KNGjXSrFmzlltPSin9+te/TnXr1k3z58/PtXXu3DlFRLr55psr9O/QoUPq3LlzhfYV+eUvf5l69+6du3/BBRekddZZJy1atCjXNmnSpFRcXJwOOuigtHjx4mWu66xZs1KDBg3SDjvskP773/8us09KKbVt2zb16dOnQh2dO3fOq/2f//xnioi0/vrrV9g28+fPr1DHlClTUklJSRo4cGCu7bbbbksRka655poKy1ta03vvvZciIt1000150w844IDUrl27vNqzXn311RQR6cQTT8xrP+ecc1JEpCeffDLX1qdPn1SvXr3lzuv7fqjvxIkTU0Sks846K9eW3X4pfTd2+/btm9c2ZcqUFBHpqquuyms/4YQTUsuWLdMXX3yR13744Yen8vLy3HOwvOdlyZIlaaONNkrdu3fP22bffPNNat++fdpzzz1zbQMGDEgRkY4//vi8ZR100EGpSZMmeW316tVb5nhZlu+v25tvvpkiIj3zzDMppZSGDBmS6tevn+bNm7fM7du5c+fUoUOHSi3n+5Zuj5EjR6aHH344FRUVpalTp6aUUjr33HPT+uuvv8z5V3bszJw5M9WuXTvtu+++edv1ggsuSBGRt20GDRqU6tWrl95///28eZ5//vmpRo0aubpS+m5sDBgwIHe/vLy8wlgBAGDN4BReAABUmyFDhsTjjz8ejz/+eNx5553RtWvXOPHEE+Pee+/N61enTp3c///zn//E7NmzY9ddd13mKWs6d+4cm2++ee7+kiVL4v7774/9999/mdc2KCoqyrt/8skn57XtuuuusXjx4vj444+XWc/cuXPjiy++iF133TW++eabePfdd/PmV1JSEscdd9wPbYof9Prrr8cbb7wRRxxxRK7tiCOOiC+++CIeffTRXNv9998fS5YsiYsuuiiKi/N335eu1+OPPx5z586N888/v8IFs7Pboyr69OmTt20ivlv/pXUsXrw4vvzyy6hfv35ssskmec/f6NGjY5111onTTz+9wnyX1rTxxhvHDjvsEHfddVdu2ldffRVjxoyJ3r17r7D2f/zjHxER0a9fv7z2s88+OyIi/v73v1dlVStt6VEjc+fOrZb5pZRi9OjRsf/++0dKKb744ovcrXv37jF79uwKr4vs8/Lqq6/GpEmT4sgjj4wvv/wy9/h58+bFHnvsEU8//XSF00j95je/ybu/6667xpdffpk7HdjK6NChQ2yxxRa5ax+NGDEievbsGXXr1l3peS/PXnvtFY0bN4577rknUkpxzz335L22vq+yY+eJJ56IhQsXxumnn543FrNHBEVEjBw5Mnbddddo1KhR3nPYrVu3WLx4cTz99NPLrb1hw4Yxfvz4+PTTT6u0zgAArHpO4QUAQLXZfvvt80KNI444Irbeeus47bTTYr/99sudWuvhhx+OSy+9NF599dUK16vIat++fd79zz//PObMmRO/+MUvKlVTmzZt8u43atQoIr4LbpZ666234sILL4wnn3yywg/Is2fPzru/7rrrVvpi5Cty5513Rr169WL99dePyZMnR0REaWlptGvXLu66667cqcw++OCDKC4uzguRsj744IOIiEpvk8rKbvuI7wKs66+/Pm688caYMmVK3nVimjRpklfTJptsUuH6N1nHHHNMnHbaafHxxx9H27ZtY+TIkbFo0aI4+uijV/i4jz/+OIqLi2PDDTfMa2/RokU0bNgwLyCrTl9//XVERDRo0KBa5vf555/HrFmz4pZbbolbbrllmX1mzpyZdz/7vEyaNCkivgtWlmf27Nm5sR+x4tdFWVlZ5VdgOY488si4+uqr46yzzornnnsuLrjggpWe54rUqlUrfvWrX8WIESNi++23j2nTpi331HWVHTtL/91oo43y+jVt2jRvW0Z89xy8/vrr0bRp02UuM/scft+VV14Zffr0idatW0fHjh1jn332iWOOOSbWX3/9Fa80AACrnAAFAIBVpri4OLp27RrXX399TJo0KTp06BDPPPNMHHDAAbHbbrvFjTfeGC1btoxatWrFsGHDKlx4OiIqHAFRVcu6gHTEd3/5H/HdhZ87d+4cZWVlMXDgwNhggw2itLQ0Xnnllfjd735X4S/3V7aepcu+++67Y968ecsMRmbOnBlff/117miH6rK8IzoWL168zO20rHW97LLL4g9/+EMcf/zxMWjQoGjcuHEUFxfHmWee+YMXy16Www8/PM4666y466674oILLog777wztt1229hkk00q9fiVOcLmx3jzzTcjIir8+P5jLd1mRx111HIDkC222CLvfvZ5WTqPq666KrbaaqtlziM7ln7odbGyjjjiiOjfv3+cdNJJ0aRJk9y1elalI488Mm6++ea4+OKLY8stt1xh6BhRvWNnyZIlseeee8Z55523zOnLul7OUoceemjsuuuucd9998Vjjz0WV111VVxxxRVx7733Ro8ePaqtRgAAqk6AAgDAKvXtt99GxP//y/3Ro0dHaWlpPProo1FSUpLrN2zYsErNr2nTplFWVpb7IXtlPfXUU/Hll1/GvffeG7vttluufcqUKVWaT1V+jB03blz8+9//joEDB8Zmm22WN+0///lPnHzyyXH//ffHUUcdFRtssEEsWbIk3n777eX+OL704t5vvvnmCn/Yb9SoUcyaNatC+8cff1zpv3YfNWpUdO3aNYYOHZrXPmvWrFhnnXXyaho/fnwsWrQoatWqtdz5NW7cOPbdd9+46667onfv3vHss8+u8ILbS7Vt2zaWLFkSkyZNytuGM2bMiFmzZkXbtm0rtT5Vdccdd0RRUVHsueee1TK/pk2bRoMGDWLx4sXRrVu3HzWPpc9/WVnZj57HsqxMwNCmTZvYeeed46mnnopTTjnlB49Eqg677LJLtGnTJp566qm44oorltuvsmNn6b+TJk3Ke318/vnneUewRXz3HHz99dc/evu3bNkyTj311Dj11FNj5syZsc0228Qf//hHAQoAQIG5BgoAAKvMokWL4rHHHovatWvnfqisUaNGFBUV5Z366aOPPor777+/UvMsLi6OAw88MB566KF46aWXKkyv6l/QL/1L/O8/buHChXHjjTdWaT716tVbZjixLEtP33XuuefGIYccknc76aSTYqONNspdF+TAAw+M4uLiGDhwYIUjPJbWvNdee0WDBg1i8ODBMX/+/GX2ifjuR94XXnghFi5cmGt7+OGHY9q0aZVezxo1alTYxiNHjoxPPvkkr61Xr17xxRdfxP/+7/9WmEf28UcffXS8/fbbce6550aNGjXi8MMP/8E69tlnn4iICmHLNddcExGROwVadbr88svjsccei8MOO6zCaZ1+rBo1akSvXr1i9OjRywwFP//88x+cR8eOHWODDTaIP/3pT7mgsqrzWJaqjOllufTSS2PAgAHLvA7OqlBUVBQ33HBDDBgwYIWngKvs2OnWrVvUqlUr/ud//idvzC4r4Dv00EPj+eefz7t+0VKzZs3KBclZixcvrnCawGbNmkWrVq3yTm8IAEBhOAIFAIBqM2bMmNxF12fOnBkjRoyISZMmxfnnn5+7rsK+++4b11xzTey9995x5JFHxsyZM2PIkCGx4YYbxuuvv16p5Vx22WXx2GOPRefOnePkk0+OzTbbLD777LMYOXJk/Otf/4qGDRtWuuaddtopGjVqFH369IkzzjgjioqK4o477qhyENOxY8e46aab4tJLL40NN9wwmjVrFrvvvnuFfgsWLIjRo0fHnnvuWeGC70sdcMABcf3118fMmTNjww03jN///vcxaNCg2HXXXePggw+OkpKSmDBhQrRq1SoGDx4cZWVlce2118aJJ54Y2223XRx55JHRqFGjeO211+Kbb76J22+/PSIiTjzxxBg1alTsvffeceihh8YHH3wQd955Z+4IhsrYb7/9YuDAgXHcccfFTjvtFG+88UbcddddFY5gOeaYY+L//u//ol+/fvHiiy/GrrvuGvPmzYsnnngiTj311OjZs2eu77777htNmjSJkSNHRo8ePaJZs2Y/WMeWW24Zffr0iVtuuSV3GrYXX3wxbr/99jjwwAOja9eulV6nrG+//TbuvPPOiIiYP39+fPzxx/Hggw/G66+/Hl27dl3utUp+rMsvvzz++c9/xg477BAnnXRSbL755vHVV1/FK6+8Ek888UR89dVXK3x8cXFx3HrrrdGjR4/o0KFDHHfccbHuuuvGJ598Ev/85z+jrKwsHnrooSrX1bFjx3jiiSfimmuuiVatWkX79u1jhx12qPTjO3fuHJ07d65U388//zwuvfTSCu3t27eP3r17V3qZPXv2zBtby1LZsdO0adM455xzYvDgwbHffvvFPvvsExMnTowxY8bkHW0VEXHuuefGgw8+GPvtt18ce+yx0bFjx5g3b1688cYbMWrUqPjoo48qPCYiYu7cubHeeuvFIYccEltuuWXUr18/nnjiiZgwYUJcffXVlV5vAABWkQQAACtp2LBhKSLybqWlpWmrrbZKN910U1qyZEle/6FDh6aNNtoolZSUpE033TQNGzYsDRgwIGV3TyMi9e3bd5nL/Pjjj9MxxxyTmjZtmkpKStL666+f+vbtmxYsWJBX04QJE/Ie989//jNFRPrnP/+Za3v22WfTjjvumOrUqZNatWqVzjvvvPToo49W6Ne5c+fUoUOHZdYzffr0tO+++6YGDRqkiEidO3deZr/Ro0eniEhDhw5d5vSUUnrqqadSRKTrr78+13bbbbelrbfeOpWUlKRGjRqlzp07p8cffzzvcQ8++GDaaaedUp06dVJZWVnafvvt0913353X5+qrr07rrrtuKikpSTvvvHN66aWXUufOnfPqXbqNRo4cWaG2+fPnp7PPPju1bNky1alTJ+28887p+eefrzCPlFL65ptv0u9///vUvn37VKtWrdSiRYt0yCGHpA8++KDCfE899dQUEWnEiBHL3S5ZixYtSpdccklu/q1bt079+/dP8+fPz+vXp0+fVK9evUrNs0+fPnnjuG7duqldu3apV69eadSoUWnx4sUVHrOsdV/W2J0yZUqKiHTVVVdVmMeMGTNS3759U+vWrXPbao899ki33HJLrs+KnpeUUpo4cWI6+OCDU5MmTVJJSUlq27ZtOvTQQ9PYsWNzfZa+zj7//PO8xy59vUyZMiXX9u6776bddtst1alTJ0VE6tOnz/I22wrX7fuW9Vx07ty5wvvH0tsee+yx3Hn90Pb4/vyzr9vKjp3FixenSy65JDfeu3Tpkt58883Utm3bCttj7ty5qX///mnDDTdMtWvXTuuss07aaaed0p/+9Ke0cOHCXL+ISAMGDEgppbRgwYJ07rnnpi233DI1aNAg1atXL2255ZbpxhtvXOE6AQCwehSlVE1XCQQAAPiRzjrrrBg6dGhMnz496tatW+hyAAAAXAMFAAAorPnz58edd94ZvXr1Ep4AAABrDNdAAQAACmLmzJnxxBNPxKhRo+LLL7+M3/72t4UuCQAAIEeAAgAAFMTbb78dvXv3jmbNmsUNN9wQW221VaFLAgAAyHENFAAAAAAAgAzXQAEAAAAAAMgQoAAAAAAAAGSs9ddAWbJkSXz66afRoEGDKCoqKnQ5AAAAAABAAaWUYu7cudGqVasoLl7+cSZrfYDy6aefRuvWrQtdBgAAAAAAsAaZNm1arLfeesudvtYHKA0aNIiI7zZEWVlZgasBAAAAAAAKac6cOdG6detcfrA8a32AsvS0XWVlZQIUAAAAAAAgIuIHL/vhIvIAAAAAAAAZAhQAAAAAAIAMAQoAAAAAAECGAAUAAAAAACBDgAIAAAAAAJAhQAEAAAAAAMgQoAAAAAAAAGQIUAAAAAAAADIEKAAAAAAAABkCFAAAAAAAgAwBCgAAAAAAQIYABQAAAAAAIEOAAgAAAAAAkCFAAQAAAAAAyBCgAAAAAAAAZAhQAAAAAAAAMgQoAAAAAAAAGQIUAAAAAACADAEKAAAAAABAhgAFAAAAAAAgQ4ACAAAAAACQIUABAAAAAADIEKAAAAAAAABkCFAAAAAAAAAyBCgAAAAAAAAZAhQAAAAAAICMmoUuAAAAAACA5SgqKnQF/JSlVOgKftIcgQIAAAAAAJAhQAEAAAAAAMgQoAAAAAAAAGQIUAAAAAAAADIEKAAAAAAAABkCFAAAAAAAgAwBCgAAAAAAQIYABQAAAAAAIEOAAgAAAAAAkCFAAQAAAAAAyBCgAAAAAAAAZNQsdAEAwPIUFboAftJSoQsAAACAnzRHoAAAAAAAAGQIUAAAAAAAADIEKAAAAAAAABkCFAAAAAAAgAwBCgAAAAAAQIYABQAAAAAAIEOAAgAAAAAAkCFAAQAAAAAAyBCgAAAAAAAAZAhQAAAAAAAAMgQoAAAAAAAAGTULXQAFVFRU6Ar4qUup0BUAAAAAAKwSjkABAAAAAADIEKAAAAAAAABkOIUXAABAFTkbLivDmXABAH4aHIECAAAAAACQIUABAAAAAADIEKAAAAAAAABkCFAAAAAAAAAyBCgAAAAAAAAZAhQAAAAAAIAMAQoAAAAAAEBGzUIuvF27dvHxxx9XaD/11FNjyJAhMX/+/Dj77LPjnnvuiQULFkT37t3jxhtvjObNmxegWgAAAADWeCOKCl0BP3VHpkJXAKwhCnoEyoQJE+Kzzz7L3R5//PGIiPjVr34VERFnnXVWPPTQQzFy5MgYN25cfPrpp3HwwQcXsmQAAAAAAOBnoKBHoDRt2jTv/uWXXx4bbLBBdO7cOWbPnh1Dhw6NESNGxO677x4REcOGDYvNNtssXnjhhdhxxx0LUTIAAAAAAPAzsMZcA2XhwoVx5513xvHHHx9FRUXx8ssvx6JFi6Jbt265Pptuumm0adMmnn/++eXOZ8GCBTFnzpy8GwAAAAAAQFWsMQHK/fffH7NmzYpjjz02IiKmT58etWvXjoYNG+b1a968eUyfPn258xk8eHCUl5fnbq1bt16FVQMAAAAAAGujNSZAGTp0aPTo0SNatWq1UvPp379/zJ49O3ebNm1aNVUIAAAAAAD8XBT0GihLffzxx/HEE0/Evffem2tr0aJFLFy4MGbNmpV3FMqMGTOiRYsWy51XSUlJlJSUrMpyAQAAAACAtdwacQTKsGHDolmzZrHvvvvm2jp27Bi1atWKsWPH5tree++9mDp1anTq1KkQZQIAAAAAAD8TBT8CZcmSJTFs2LDo06dP1Kz5/8spLy+PE044Ifr16xeNGzeOsrKyOP3006NTp06x4447FrBiYI01oqjQFfBTd2QqdAWw1iq6xHs0KycN8B4NAACsXgUPUJ544omYOnVqHH/88RWmXXvttVFcXBy9evWKBQsWRPfu3ePGG28sQJUAAAAAAMDPScEDlL322itSWvZfk5WWlsaQIUNiyJAhq7kqAAAAAADg52yNuAYKAAAAAADAmkSAAgAAAAAAkCFAAQAAAAAAyBCgAAAAAAAAZAhQAAAAAAAAMgQoAAAAAAAAGQIUAAAAAACADAEKAAAAAABAhgAFAAAAAAAgQ4ACAAAAAACQIUABAAAAAADIEKAAAAAAAABkCFAAAAAAAAAyBCgAAAAAAAAZAhQAAAAAAIAMAQoAAAAAAECGAAUAAAAAACBDgAIAAAAAAJAhQAEAAAAAAMgQoAAAAAAAAGQIUAAAAAAAADIEKAAAAAAAABkCFAAAAAAAgAwBCgAAAAAAQEbNQhcAAAAAFNi7RYWugJ+yTVOhKwCAVcIRKAAAAAAAABkCFAAAAAAAgAwBCgAAAAAAQIYABQAAAAAAIEOAAgAAAAAAkCFAAQAAAAAAyBCgAAAAAAAAZAhQAAAAAAAAMgQoAAAAAAAAGQIUAAAAAACADAEKAAAAAABAhgAFAAAAAAAgQ4ACAAAAAACQIUABAAAAAADIEKAAAAAAAABkCFAAAAAAAAAyBCgAAAAAAAAZAhQAAAAAAIAMAQoAAAAAAECGAAUAAAAAACBDgAIAAAAAAJAhQAEAAAAAAMgQoAAAAAAAAGQIUAAAAAAAADIEKAAAAAAAABkCFAAAAAAAgAwBCgAAAAAAQIYABQAAAAAAIEOAAgAAAAAAkCFAAQAAAAAAyBCgAAAAAAAAZAhQAAAAAAAAMgQoAAAAAAAAGQIUAAAAAACADAEKAAAAAABAhgAFAAAAAAAgQ4ACAAAAAACQIUABAAAAAADIEKAAAAAAAABkCFAAAAAAAAAyBCgAAAAAAAAZAhQAAAAAAICMggcon3zySRx11FHRpEmTqFOnTvzyl7+Ml156KTc9pRQXXXRRtGzZMurUqRPdunWLSZMmFbBiAAAAAABgbVfQAOU///lP7LzzzlGrVq0YM2ZMvP3223H11VdHo0aNcn2uvPLKuOGGG+Lmm2+O8ePHR7169aJ79+4xf/78AlYOAAAAAACszWoWcuFXXHFFtG7dOoYNG5Zra9++fe7/KaW47rrr4sILL4yePXtGRMT//d//RfPmzeP++++Pww8/fLXXDAAAAAAArP0KegTKgw8+GNtuu2386le/imbNmsXWW28df/nLX3LTp0yZEtOnT49u3brl2srLy2OHHXaI559/fpnzXLBgQcyZMyfvBgAAAAAAUBUFDVA+/PDDuOmmm2KjjTaKRx99NE455ZQ444wz4vbbb4+IiOnTp0dERPPmzfMe17x589y0rMGDB0d5eXnu1rp161W7EgAAAAAAwFqnoAHKkiVLYptttonLLrsstt566zj55JPjpJNOiptvvvlHz7N///4xe/bs3G3atGnVWDEAAAAAAPBzUNAApWXLlrH55pvntW222WYxderUiIho0aJFRETMmDEjr8+MGTNy07JKSkqirKws7wYAAAAAAFAVBQ1Qdt5553jvvffy2t5///1o27ZtRHx3QfkWLVrE2LFjc9PnzJkT48ePj06dOq3WWgEAAAAAgJ+PmoVc+FlnnRU77bRTXHbZZXHooYfGiy++GLfcckvccsstERFRVFQUZ555Zlx66aWx0UYbRfv27eMPf/hDtGrVKg488MBClg4AAAAAAKzFChqgbLfddnHfffdF//79Y+DAgdG+ffu47rrronfv3rk+5513XsybNy9OPvnkmDVrVuyyyy7xyCOPRGlpaQErBwAAAAAA1mZFKaVU6CJWpTlz5kR5eXnMnj3b9VCyiooKXQE/dWva28cIY5qVdOQaNqbDmGZlrFnjuegS45mVkwasYWPakGYlrGm70RER8a5BzUrYdA0b1L4bsrLWtO+GdjxYGWvkjkfhVTY3KOg1UAAAAAAAANZEAhQAAAAAAIAMAQoAAAAAAECGAAUAAAAAACBDgAIAAAAAAJAhQAEAAAAAAMgQoAAAAAAAAGQIUAAAAAAAADIEKAAAAAAAABkCFAAAAAAAgAwBCgAAAAAAQIYABQAAAAAAIEOAAgAAAAAAkCFAAQAAAAAAyBCgAAAAAAAAZAhQAAAAAAAAMgQoAAAAAAAAGQIUAAAAAACADAEKAAAAAABAhgAFAAAAAAAgQ4ACAAAAAACQIUABAAAAAADIEKAAAAAAAABkCFAAAAAAAAAyBCgAAAAAAAAZAhQAAAAAAIAMAQoAAAAAAECGAAUAAAAAACBDgAIAAAAAAJAhQAEAAAAAAMgQoAAAAAAAAGQIUAAAAAAAADIEKAAAAAAAABkCFAAAAAAAgAwBCgAAAAAAQIYABQAAAAAAIEOAAgAAAAAAkCFAAQAAAAAAyBCgAAAAAAAAZAhQAAAAAAAAMgQoAAAAAAAAGQIUAAAAAACADAEKAAAAAABAhgAFAAAAAAAgQ4ACAAAAAACQIUABAAAAAADIEKAAAAAAAABkCFAAAAAAAAAyBCgAAAAAAAAZAhQAAAAAAIAMAQoAAAAAAECGAAUAAAAAACBDgAIAAAAAAJAhQAEAAAAAAMgQoAAAAAAAAGQIUAAAAAAAADIEKAAAAAAAABkCFAAAAAAAgAwBCgAAAAAAQIYABQAAAAAAIEOAAgAAAAAAkCFAAQAAAAAAyBCgAAAAAAAAZAhQAAAAAAAAMgQoAAAAAAAAGQIUAAAAAACADAEKAAAAAABAhgAFAAAAAAAgo6ABysUXXxxFRUV5t0033TQ3ff78+dG3b99o0qRJ1K9fP3r16hUzZswoYMUAAAAAAMDPQcGPQOnQoUN89tlnudu//vWv3LSzzjorHnrooRg5cmSMGzcuPv300zj44IMLWC0AAAAAAPBzULPgBdSsGS1atKjQPnv27Bg6dGiMGDEidt9994iIGDZsWGy22WbxwgsvxI477ri6SwUAAAAAAH4mCn4EyqRJk6JVq1ax/vrrR+/evWPq1KkREfHyyy/HokWLolu3brm+m266abRp0yaef/755c5vwYIFMWfOnLwbAAAAAABAVRQ0QNlhhx1i+PDh8cgjj8RNN90UU6ZMiV133TXmzp0b06dPj9q1a0fDhg3zHtO8efOYPn36cuc5ePDgKC8vz91at269itcCAAAAAABY2xT0FF49evTI/X+LLbaIHXbYIdq2bRt/+9vfok6dOj9qnv37949+/frl7s+ZM0eIAgAAAAAAVEnBT+H1fQ0bNoyNN944Jk+eHC1atIiFCxfGrFmz8vrMmDFjmddMWaqkpCTKysrybgAAAAAAAFWxRgUoX3/9dXzwwQfRsmXL6NixY9SqVSvGjh2bm/7ee+/F1KlTo1OnTgWsEgAAAAAAWNsV9BRe55xzTuy///7Rtm3b+PTTT2PAgAFRo0aNOOKII6K8vDxOOOGE6NevXzRu3DjKysri9NNPj06dOsWOO+5YyLIBAAAAAIC1XEEDlH//+99xxBFHxJdffhlNmzaNXXbZJV544YVo2rRpRERce+21UVxcHL169YoFCxZE9+7d48YbbyxkyQAAAAAAwM9AQQOUe+65Z4XTS0tLY8iQITFkyJDVVBEAAAAAAMAadg0UAAAAAACANYEABQAAAAAAIEOAAgAAAAAAkCFAAQAAAAAAyBCgAAAAAAAAZAhQAAAAAAAAMgQoAAAAAAAAGQIUAAAAAACADAEKAAAAAABAhgAFAAAAAAAgQ4ACAAAAAACQIUABAAAAAADIEKAAAAAAAABkCFAAAAAAAAAyBCgAAAAAAAAZAhQAAAAAAIAMAQoAAAAAAECGAAUAAAAAACBDgAIAAAAAAJAhQAEAAAAAAMgQoAAAAAAAAGQIUAAAAAAAADIEKAAAAAAAABkCFAAAAAAAgAwBCgAAAAAAQIYABQAAAAAAIEOAAgAAAAAAkCFAAQAAAAAAyBCgAAAAAAAAZAhQAAAAAAAAMgQoAAAAAAAAGQIUAAAAAACADAEKAAAAAABAhgAFAAAAAAAgQ4ACAAAAAACQIUABAAAAAADIEKAAAAAAAABkVDlAGTZsWHzzzTerohYAAAAAAIA1QpUDlPPPPz9atGgRJ5xwQjz33HOroiYAAAAAAICCqnKA8sknn8Ttt98eX3zxRXTp0iU23XTTuOKKK2L69Omroj4AAAAAAIDVrsoBSs2aNeOggw6KBx54IKZNmxYnnXRS3HXXXdGmTZs44IAD4oEHHoglS5asiloBAAAAAABWi5W6iHzz5s1jl112iU6dOkVxcXG88cYb0adPn9hggw3iqaeeqqYSAQAAAAAAVq8fFaDMmDEj/vSnP0WHDh2iS5cuMWfOnHj44YdjypQp8cknn8Shhx4affr0qe5aAQAAAAAAVosqByj7779/tG7dOoYPHx4nnXRSfPLJJ3H33XdHt27dIiKiXr16cfbZZ8e0adOqvVgAAAAAAIDVoWZVH9CsWbMYN25cdOrUabl9mjZtGlOmTFmpwgAAAAAAAAqlygHK0KFDf7BPUVFRtG3b9kcVBAAAAAAAUGhVPoXXGWecETfccEOF9v/93/+NM888szpqAgAAAAAAKKgqByijR4+OnXfeuUL7TjvtFKNGjaqWogAAAAAAAAqpygHKl19+GeXl5RXay8rK4osvvqiWogAAAAAAAAqpygHKhhtuGI888kiF9jFjxsT6669fLUUBAAAAAAAUUpUvIt+vX7847bTT4vPPP4/dd989IiLGjh0bV199dVx33XXVXR8AAAAAAMBqV+UA5fjjj48FCxbEH//4xxg0aFBERLRr1y5uuummOOaYY6q9QAAAAAAAgNWtygFKRMQpp5wSp5xySnz++edRp06dqF+/fnXXBQAAAAAAUDA/KkBZqmnTptVVBwAAAAAAwBrjRwUoo0aNir/97W8xderUWLhwYd60V155pVoKAwAAAAAAKJTiqj7ghhtuiOOOOy6aN28eEydOjO233z6aNGkSH374YfTo0WNV1AgAAAAAALBaVTlAufHGG+OWW26J//mf/4natWvHeeedF48//nicccYZMXv27FVRIwAAAAAAwGpV5QBl6tSpsdNOO0VERJ06dWLu3LkREXH00UfH3XffXb3VAQAAAAAAFECVA5QWLVrEV199FRERbdq0iRdeeCEiIqZMmRIppeqtDgAAAAAAoACqHKDsvvvu8eCDD0ZExHHHHRdnnXVW7LnnnnHYYYfFQQcdVO0FAgAAAAAArG41q/qAW265JZYsWRIREX379o0mTZrEc889FwcccED8+te/rvYCAQAAAAAAVrcqBSjffvttXHbZZXH88cfHeuutFxERhx9+eBx++OGrpDgAAAAAAIBCqNIpvGrWrBlXXnllfPvtt6uqHgAAAAAAgIKr8jVQ9thjjxg3btyqqAUAAAAAAGCNUOVroPTo0SPOP//8eOONN6Jjx45Rr169vOkHHHBAtRUHAAAAAABQCFUOUE499dSIiLjmmmsqTCsqKorFixevfFUAAAAAAAAFVOUAZcmSJauiDgAAAAAAgDVGla+BsqpcfvnlUVRUFGeeeWaubf78+dG3b99o0qRJ1K9fP3r16hUzZswoXJEAAAAAAMDPQpWPQBk4cOAKp1900UVVLmLChAnx5z//ObbYYou89rPOOiv+/ve/x8iRI6O8vDxOO+20OPjgg+PZZ5+t8jIAAAAAAAAqq8oByn333Zd3f9GiRTFlypSoWbNmbLDBBlUOUL7++uvo3bt3/OUvf4lLL7001z579uwYOnRojBgxInbfffeIiBg2bFhsttlm8cILL8SOO+5Y1dIBAAAAAAAqpcoBysSJEyu0zZkzJ4499tg46KCDqlxA3759Y999941u3brlBSgvv/xyLFq0KLp165Zr23TTTaNNmzbx/PPPLzdAWbBgQSxYsCCvNgAAAAAAgKqolmuglJWVxSWXXBJ/+MMfqvS4e+65J1555ZUYPHhwhWnTp0+P2rVrR8OGDfPamzdvHtOnT1/uPAcPHhzl5eW5W+vWratUEwAAAAAAQLVdRH727Nkxe/bsSvefNm1a/Pa3v4277rorSktLq6uM6N+/f66W2bNnx7Rp06pt3gAAAAAAwM9DlU/hdcMNN+TdTynFZ599FnfccUf06NGj0vN5+eWXY+bMmbHNNtvk2hYvXhxPP/10/O///m88+uijsXDhwpg1a1beUSgzZsyIFi1aLHe+JSUlUVJSUvkVAgAAAAAAyKhygHLttdfm3S8uLo6mTZtGnz59on///pWezx577BFvvPFGXttxxx0Xm266afzud7+L1q1bR61atWLs2LHRq1eviIh47733YurUqdGpU6eqlg0AAAAAAFBpVQ5QpkyZUi0LbtCgQfziF7/Ia6tXr140adIk137CCSdEv379onHjxlFWVhann356dOrUabkXkAcAAAAAAKgOVQ5QZs+eHYsXL47GjRvntX/11VdRs2bNKCsrq7birr322iguLo5evXrFggULonv37nHjjTdW2/wBAAAAAACWpcoXkT/88MPjnnvuqdD+t7/9LQ4//PCVKuapp56K6667Lne/tLQ0hgwZEl999VXMmzcv7r333hVe/wQAAAAAAKA6VDlAGT9+fHTt2rVCe5cuXWL8+PHVUhQAAAAAAEAhVTlAWbBgQXz77bcV2hctWhT//e9/q6UoAAAAAACAQqpygLL99tvHLbfcUqH95ptvjo4dO1ZLUQAAAAAAAIVU5YvIX3rppdGtW7d47bXXYo899oiIiLFjx8aECRPiscceq/YCAQAAAAAAVrcqH4Gy8847x/PPPx+tW7eOv/3tb/HQQw/FhhtuGK+//nrsuuuuq6JGAAAAAACA1arKR6BERGy11VZx1113VXctAAAAAAAAa4QqH4Hyj3/8Ix599NEK7Y8++miMGTOmWooCAAAAAAAopCoHKOeff34sXry4QntKKc4///xqKQoAAAAAAKCQqhygTJo0KTbffPMK7ZtuumlMnjy5WooCAAAAAAAopCoHKOXl5fHhhx9WaJ88eXLUq1evWooCAAAAAAAopCoHKD179owzzzwzPvjgg1zb5MmT4+yzz44DDjigWosDAAAAAAAohCoHKFdeeWXUq1cvNt1002jfvn20b98+Nttss2jSpElcddVVq6JGAAAAAACA1apmVR9QXl4ezz33XDz++OPx2muvRZ06dWKLLbaI3XbbbVXUBwAAAAAAsNpVOUCJiCgqKoq99tor9tprr4iISCnFmDFjYujQoTFq1KhqLRAAAAAAAGB1q/IpvL5vypQp8Yc//CHatGkTBx10UMyfP7+66gIAAAAAACiYKh+BsmDBghg1alQMHTo0/vWvf8XixYvjT3/6U5xwwglRVla2KmoEAAAAAABYrSp9BMrLL78cp556arRo0SKuu+66OPDAA2PatGlRXFwc3bt3F54AAAAAAABrjUofgbLDDjvE6aefHi+88EJssskmq7ImAAAAAACAgqp0gLLHHnvE0KFDY+bMmXH00UdH9+7do6ioaFXWBgAAAAAAUBCVPoXXo48+Gm+99VZssskmccopp0TLli3jt7/9bUSEIAUAAAAAAFirVDpAiYho3bp1XHTRRTFlypS444474vPPP4+aNWtGz54944ILLohXXnllVdUJAAAAAACw2lQpQPm+PffcM0aMGBGffvppnH766TFmzJjYbrvtqrM2AAAAAACAgvjRAcpSjRo1itNPPz0mTpwYEyZMqI6aAAAAAAAACmqlA5Tv22abbapzdgAAAAAAAAVRrQEKAAAAAADA2kCAAgAAAAAAkCFAAQAAAAAAyKi5Mg/+4osvYvz48bF48eLYbrvtomXLltVVFwAAAAAAQMH86ABl9OjRccIJJ8TGG28cixYtivfeey+GDBkSxx13XHXWBwAAAAAAsNpV+hReX3/9dd79Sy65JF588cV48cUXY+LEiTFy5Mj4/e9/X+0FAgAAAAAArG6VDlA6duwYDzzwQO5+zZo1Y+bMmbn7M2bMiNq1a1dvdQAAAAAAAAVQ6VN4Pfroo9G3b98YPnx4DBkyJK6//vo47LDDYvHixfHtt99GcXFxDB8+fBWWCgAAAAAAsHpUOkBp165d/P3vf4+77747OnfuHGeccUZMnjw5Jk+eHIsXL45NN900SktLV2WtAAAAAAAAq0WlT+G11BFHHBETJkyI1157Lbp06RJLliyJrbbaSngCAAAAAACsNSp9BEpExD/+8Y945513Ysstt4xbb701xo0bF717944ePXrEwIEDo06dOquqTgAAAAAAgNWm0kegnH322XHcccfFhAkT4te//nUMGjQoOnfuHK+88kqUlpbG1ltvHWPGjFmVtQIAAAAAAKwWlQ5Qhg8fHv/4xz/innvuiQkTJsQdd9wRERG1a9eOQYMGxb333huXXXbZKisUAAAAAABgdal0gFKvXr2YMmVKRERMmzatwjVPNt9883jmmWeqtzoAAAAAAIACqHSAMnjw4DjmmGOiVatW0blz5xg0aNCqrAsAAAAAAKBgKn0R+d69e8fee+8dH374YWy00UbRsGHDVVgWAAAAAABA4VQ6QImIaNKkSTRp0mRV1QIAAAAAALBGqPQpvAAAAAAAAH4uBCgAAAAAAAAZAhQAAAAAAIAMAQoAAAAAAECGAAUAAAAAACBDgAIAAAAAAJAhQAEAAAAAAMgQoAAAAAAAAGQIUAAAAAAAADIEKAAAAAAAABkCFAAAAAAAgAwBCgAAAAAAQIYABQAAAAAAIEOAAgAAAAAAkCFAAQAAAAAAyBCgAAAAAAAAZAhQAAAAAAAAMgQoAAAAAAAAGQIUAAAAAACADAEKAAAAAABAhgAFAAAAAAAgQ4ACAAAAAACQIUABAAAAAADIEKAAAAAAAABkCFAAAAAAAAAyBCgAAAAAAAAZBQ1Qbrrppthiiy2irKwsysrKolOnTjFmzJjc9Pnz50ffvn2jSZMmUb9+/ejVq1fMmDGjgBUDAAAAAAA/BwUNUNZbb724/PLL4+WXX46XXnopdt999+jZs2e89dZbERFx1llnxUMPPRQjR46McePGxaeffhoHH3xwIUsGAAAAAAB+BmoWcuH7779/3v0//vGPcdNNN8ULL7wQ6623XgwdOjRGjBgRu+++e0REDBs2LDbbbLN44YUXYscddyxEyQAAAAAAwM/AGnMNlMWLF8c999wT8+bNi06dOsXLL78cixYtim7duuX6bLrpptGmTZt4/vnnlzufBQsWxJw5c/JuAAAAAAAAVVHwAOWNN96I+vXrR0lJSfzmN7+J++67LzbffPOYPn161K5dOxo2bJjXv3nz5jF9+vTlzm/w4MFRXl6eu7Vu3XoVrwEAAAAAALC2KXiAsskmm8Srr74a48ePj1NOOSX69OkTb7/99o+eX//+/WP27Nm527Rp06qxWgAAAAAA4OegoNdAiYioXbt2bLjhhhER0bFjx5gwYUJcf/31cdhhh8XChQtj1qxZeUehzJgxI1q0aLHc+ZWUlERJScmqLhsAAAAAAFiLFfwIlKwlS5bEggULomPHjlGrVq0YO3Zsbtp7770XU6dOjU6dOhWwQgAAAAAAYG1X0CNQ+vfvHz169Ig2bdrE3LlzY8SIEfHUU0/Fo48+GuXl5XHCCSdEv379onHjxlFWVhann356dOrUKXbcccdClg0AAAAAAKzlChqgzJw5M4455pj47LPPory8PLbYYot49NFHY88994yIiGuvvTaKi4ujV69esWDBgujevXvceOONhSwZAAAAAAD4GShogDJ06NAVTi8tLY0hQ4bEkCFDVlNFAAAAAAAAa+A1UAAAAAAAAApNgAIAAAAAAJAhQAEAAAAAAMgQoAAAAAAAAGQIUAAAAAAAADIEKAAAAAAAABkCFAAAAAAAgAwBCgAAAAAAQIYABQAAAAAAIEOAAgAAAAAAkCFAAQAAAAAAyBCgAAAAAAAAZAhQAAAAAAAAMgQoAAAAAAAAGQIUAAAAAACADAEKAAAAAABAhgAFAAAAAAAgQ4ACAAAAAACQIUABAAAAAADIEKAAAAAAAABkCFAAAAAAAAAyBCgAAAAAAAAZAhQAAAAAAIAMAQoAAAAAAECGAAUAAAAAACBDgAIAAAAAAJAhQAEAAAAAAMgQoAAAAAAAAGQIUAAAAAAAADIEKAAAAAAAABkCFAAAAAAAgAwBCgAAAAAAQIYABQAAAAAAIEOAAgAAAAAAkCFAAQAAAAAAyBCgAAAAAAAAZAhQAAAAAAAAMgQoAAAAAAAAGQIUAAAAAACADAEKAAAAAABAhgAFAAAAAAAgQ4ACAAAAAACQIUABAAAAAADIEKAAAAAAAABkCFAAAAAAAAAyBCgAAAAAAAAZAhQAAAAAAIAMAQoAAAAAAECGAAUAAAAAACBDgAIAAAAAAJAhQAEAAAAAAMgQoAAAAAAAAGQIUAAAAAAAADIEKAAAAAAAABkCFAAAAAAAgAwBCgAAAAAAQIYABQAAAAAAIEOAAgAAAAAAkCFAAQAAAAAAyBCgAAAAAAAAZAhQAAAAAAAAMgQoAAAAAAAAGQIUAAAAAACADAEKAAAAAABAhgAFAAAAAAAgQ4ACAAAAAACQIUABAAAAAADIKGiAMnjw4Nhuu+2iQYMG0axZszjwwAPjvffey+szf/786Nu3bzRp0iTq168fvXr1ihkzZhSoYgAAAAAA4OegoAHKuHHjom/fvvHCCy/E448/HosWLYq99tor5s2bl+tz1llnxUMPPRQjR46McePGxaeffhoHH3xwAasGAAAAAADWdjULufBHHnkk7/7w4cOjWbNm8fLLL8duu+0Ws2fPjqFDh8aIESNi9913j4iIYcOGxWabbRYvvPBC7LjjjoUoGwAAAAAAWMutUddAmT17dkRENG7cOCIiXn755Vi0aFF069Yt12fTTTeNNm3axPPPP7/MeSxYsCDmzJmTdwMAAAAAAKiKNSZAWbJkSZx55pmx8847xy9+8YuIiJg+fXrUrl07GjZsmNe3efPmMX369GXOZ/DgwVFeXp67tW7delWXDgAAAAAArGXWmAClb9++8eabb8Y999yzUvPp379/zJ49O3ebNm1aNVUIAAAAAAD8XBT0GihLnXbaafHwww/H008/Heutt16uvUWLFrFw4cKYNWtW3lEoM2bMiBYtWixzXiUlJVFSUrKqSwYAAAAAANZiBT0CJaUUp512Wtx3333x5JNPRvv27fOmd+zYMWrVqhVjx47Ntb333nsxderU6NSp0+ouFwAAAAAA+Jko6BEoffv2jREjRsQDDzwQDRo0yF3XpLy8POrUqRPl5eVxwgknRL9+/aJx48ZRVlYWp59+enTq1Cl23HHHQpYOAAAAAACsxQoaoNx0000REdGlS5e89mHDhsWxxx4bERHXXnttFBcXR69evWLBggXRvXv3uPHGG1dzpQAAAAAAwM9JQQOUlNIP9iktLY0hQ4bEkCFDVkNFAAAAAAAABb4GCgAAAAAAwJpIgAIAAAAAAJAhQAEAAAAAAMgQoAAAAAAAAGQIUAAAAAAAADIEKAAAAAAAABkCFAAAAAAAgAwBCgAAAAAAQIYABQAAAAAAIEOAAgAAAAAAkCFAAQAAAAAAyBCgAAAAAAAAZAhQAAAAAAAAMgQoAAAAAAAAGQIUAAAAAACADAEKAAAAAABAhgAFAAAAAAAgQ4ACAAAAAACQIUABAAAAAADIEKAAAAAAAABkCFAAAAAAAAAyBCgAAAAAAAAZAhQAAAAAAIAMAQoAAAAAAECGAAUAAAAAACBDgAIAAAAAAJAhQAEAAAAAAMgQoAAAAAAAAGQIUAAAAAAAADIEKAAAAAAAABkCFAAAAAAAgAwBCgAAAAAAQIYABQAAAAAAIEOAAgAAAAAAkCFAAQAAAAAAyBCgAAAAAAAAZAhQAAAAAAAAMgQoAAAAAAAAGQIUAAAAAACADAEKAAAAAABAhgAFAAAAAAAgQ4ACAAAAAACQIUABAAAAAADIEKAAAAAAAABkCFAAAAAAAAAyBCgAAAAAAAAZAhQAAAAAAIAMAQoAAAAAAECGAAUAAAAAACBDgAIAAAAAAJAhQAEAAAAAAMgQoAAAAAAAAGQIUAAAAAAAADIEKAAAAAAAABkCFAAAAAAAgAwBCgAAAAAAQIYABQAAAAAAIEOAAgAAAAAAkCFAAQAAAAAAyBCgAAAAAAAAZAhQAAAAAAAAMgQoAAAAAAAAGQIUAAAAAACADAEKAAAAAABAhgAFAAAAAAAgQ4ACAAAAAACQIUABAAAAAADIEKAAAAAAAABkFDRAefrpp2P//fePVq1aRVFRUdx///1501NKcdFFF0XLli2jTp060a1bt5g0aVJhigUAAAAAAH42ChqgzJs3L7bccssYMmTIMqdfeeWVccMNN8TNN98c48ePj3r16kX37t1j/vz5q7lSAAAAAADg56RmIRfeo0eP6NGjxzKnpZTiuuuuiwsvvDB69uwZERH/93//F82bN4/7778/Dj/88NVZKgAAAAAA8DOyxl4DZcqUKTF9+vTo1q1brq28vDx22GGHeP7555f7uAULFsScOXPybgAAAAAAAFWxxgYo06dPj4iI5s2b57U3b948N21ZBg8eHOXl5blb69atV2mdAAAAAADA2meNDVB+rP79+8fs2bNzt2nTphW6JAAAAAAA4CdmjQ1QWrRoERERM2bMyGufMWNGbtqylJSURFlZWd4NAAAAAACgKtbYAKV9+/bRokWLGDt2bK5tzpw5MX78+OjUqVMBKwMAAAAAANZ2NQu58K+//jomT56cuz9lypR49dVXo3HjxtGmTZs488wz49JLL42NNtoo2rdvH3/4wx+iVatWceCBBxauaAAAAAAAYK1X0ADlpZdeiq5du+bu9+vXLyIi+vTpE8OHD4/zzjsv5s2bFyeffHLMmjUrdtlll3jkkUeitLS0UCUDAAAAAAA/AwUNULp06RIppeVOLyoqioEDB8bAgQNXY1UAAAAAAMDP3Rp7DRQAAAAAAIBCEaAAAAAAAABkCFAAAAAAAAAyBCgAAAAAAAAZAhQAAAAAAIAMAQoAAAAAAECGAAUAAAAAACBDgAIAAAAAAJAhQAEAAAAAAMgQoAAAAAAAAGQIUAAAAAAAADIEKAAAAAAAABkCFAAAAAAAgAwBCgAAAAAAQIYABQAAAAAAIEOAAgAAAAAAkCFAAQAAAAAAyBCgAAAAAAAAZAhQAAAAAAAAMgQoAAAAAAAAGQIUAAAAAACADAEKAAAAAABAhgAFAAAAAAAgQ4ACAAAAAACQIUABAAAAAADIEKAAAAAAAABkCFAAAAAAAAAyBCgAAAAAAAAZAhQAAAAAAIAMAQoAAAAAAECGAAUAAAAAACBDgAIAAAAAAJAhQAEAAAAAAMgQoAAAAAAAAGQIUAAAAAAAADIEKAAAAAAAABkCFAAAAAAAgAwBCgAAAAAAQIYABQAAAAAAIEOAAgAAAAAAkCFAAQAAAAAAyBCgAAAAAAAAZAhQAAAAAAAAMgQoAAAAAAAAGQIUAAAAAACADAEKAAAAAABAhgAFAAAAAAAgQ4ACAAAAAACQIUABAAAAAADIEKAAAAAAAABkCFAAAAAAAAAyBCgAAAAAAAAZAhQAAAAAAIAMAQoAAAAAAECGAAUAAAAAACBDgAIAAAAAAJAhQAEAAAAAAMgQoAAAAAAAAGQIUAAAAAAAADIEKAAAAAAAABkCFAAAAAAAgAwBCgAAAAAAQIYABQAAAAAAIEOAAgAAAAAAkCFAAQAAAAAAyBCgAAAAAAAAZAhQAAAAAAAAMn4SAcqQIUOiXbt2UVpaGjvssEO8+OKLhS4JAAAAAABYi63xAcpf//rX6NevXwwYMCBeeeWV2HLLLaN79+4xc+bMQpcGAAAAAACspdb4AOWaa66Jk046KY477rjYfPPN4+abb466devGbbfdVujSAAAAAACAtVTNQhewIgsXLoyXX345+vfvn2srLi6Obt26xfPPP7/MxyxYsCAWLFiQuz979uyIiJgzZ86qLRZ+jta019U3hS6An7w1bUzDSlnDxvP8QhfAT539edYma+Rw/rrQBfCTtqYNat8NWVlr2piGlWE8L9PS7xcppRX2W6MDlC+++CIWL14czZs3z2tv3rx5vPvuu8t8zODBg+OSSy6p0N66detVUiP8rJWXF7oCqF4nGdOsTYxn1i7llxvTrD3sRrP2MahZy/huyNrEjscKzZ07N8pXsI3W6ADlx+jfv3/069cvd3/JkiXx1VdfRZMmTaKoqKiAlfFTM2fOnGjdunVMmzYtysrKCl0OrBTjmbWNMc3axphmbWI8s7YxplnbGNOsTYxnfqyUUsydOzdatWq1wn5rdICyzjrrRI0aNWLGjBl57TNmzIgWLVos8zElJSVRUlKS19awYcNVVSI/A2VlZd6AWWsYz6xtjGnWNsY0axPjmbWNMc3axphmbWI882Os6MiTpdboi8jXrl07OnbsGGPHjs21LVmyJMaOHRudOnUqYGUAAAAAAMDabI0+AiUiol+/ftGnT5/YdtttY/vtt4/rrrsu5s2bF8cdd1yhSwMAAAAAANZSa3yActhhh8Xnn38eF110UUyfPj222mqreOSRRypcWB6qW0lJSQwYMKDCKeHgp8h4Zm1jTLO2MaZZmxjPrG2MadY2xjRrE+OZVa0opZQKXQQAAAAAAMCaZI2+BgoAAAAAAEAhCFAAAAAAAAAyBCgAAAAAAAAZAhQKpl27dnHdddf96McPHz48GjZsWG31rE1WdttSOF26dIkzzzyz0GXAKlNUVBT3339/octgLfHRRx9FUVFRvPrqq5V+zLHHHhsHHnjgKqtpdfkx6/5jLWuf65ZbbonWrVtHcXFxXHfddXHxxRfHVltttcpr4eerqp8fTz31VBQVFcWsWbOW28e4/Xmoyncj36Pgp60y7+u+c/98rE3v6VXdZ1md3xV+DgQoLNPq+HFhwoQJcfLJJ1eq77Le9A477LB4//33f/Tyhw8fHkVFRVFUVBTFxcXRsmXLOOyww2Lq1Kk/ep5riqpsW1bescceG0VFRXH55Zfntd9///1RVFRUpXnde++9MWjQoOosr4Kl9S69NWnSJPbee+94/fXXV+lyWTN8//mvVatWtG/fPs4777yYP39+oUtbpbLjfult8uTJBa1pbfghn6r7qT332X2uOXPmxGmnnRa/+93v4pNPPomTTz45zjnnnBg7dmwBqyycZT2fo0aNitLS0rj66qsr9F/6w36HDh1i8eLFedMaNmwYw4cPX4XVVo/K/vjUpUuXKCoqinvuuSev/brrrot27dpVaZmfffZZ9OjRo0qPYc2V3R9p3rx57LnnnnHbbbfFkiVLqnVZVflutKq/Ry1vf2Tpraqvi5+jzz//PE455ZRo06ZNlJSURIsWLaJ79+7x7LPPFrq0SqtMwDt69OioUaNGfPLJJ8ucvtFGG0W/fv1WupZV/QPz0jH/m9/8psK0vn37RlFRURx77LGrbPnLsjq+c1eX1fle+WOtyfu1q+u3sXbt2i1zfyciokOHDlFUVPST2L9j+QQoFEzTpk2jbt26P/rxderUiWbNmq1UDWVlZfHZZ5/FJ598EqNHj4733nsvfvWrX63UPCtj0aJFq3T+K7ttqbrS0tK44oor4j//+c9Kzadx48bRoEGDaqpq+fbee+/47LPP4rPPPouxY8dGzZo1Y7/99lvly2XNsPT5//DDD+Paa6+NP//5zzFgwIBCl7XKfX/cL721b9/+R81r4cKF1VwdrLmy+1xTp06NRYsWxb777hstW7aMunXrRv369aNJkyYrtZxVvX+0utx6663Ru3fvuOmmm+Lss89ebr8PP/ww/u///m81Vvad1f3+VVpaGhdeeOFKP78tWrSIkpKSaqqqsBYvXrzG/PBVSEs/lz/66KMYM2ZMdO3aNX7729/GfvvtF99++221Lacq341W9feo66+/Pm8/JCJi2LBhufsTJkzI629/o6JevXrFxIkT4/bbb4/3338/HnzwwejSpUt8+eWXhS6tUir7XnjAAQdEkyZN4vbbb68w7emnn47JkyfHCSecUN3l/WgrGqutW7eOe+65J/773//m2ubPnx8jRoyINm3arI7y8qyu79zVZXW9V/6UVPZ1tDp/G2vdunUMGzYsr+2FF16I6dOnR7169VZLDaw6AhR+lHHjxsX2228fJSUl0bJlyzj//PPz3rjnzp0bvXv3jnr16kXLli3j2muvrfCXat//S4eUUlx88cW5vyJp1apVnHHGGRHx3V+uffzxx3HWWWflkveIZZ9O4qGHHortttsuSktLY5111omDDjpohetRVFQULVq0iJYtW8ZOO+0UJ5xwQrz44osxZ86cXJ8HHnggttlmmygtLY31118/Lrnkkrx1fffdd2OXXXaJ0tLS2HzzzeOJJ57IO8XA0sPm/vrXv0bnzp2jtLQ07rrrroj47gv2ZpttFqWlpbHpppvGjTfemJvvwoUL47TTTouWLVtGaWlptG3bNgYPHvyD2yu7bSO++6GjZ8+eUb9+/SgrK4tDDz00ZsyYkZu+9FDAO+64I9q1axfl5eVx+OGHx9y5c1e4/fj/unXrFi1atMg9R8vy5ZdfxhFHHBHrrrtu1K1bN375y1/G3Xffndfn+6+TCy64IHbYYYcK89lyyy1j4MCBufsrGkfLs/SvtVq0aBFbbbVVnH/++TFt2rT4/PPPc31+97vfxcYbbxx169aN9ddfP/7whz/kdlQ++uijKC4ujpdeeilvvtddd120bds296PAm2++GT169Ij69etH8+bN4+ijj44vvvgi13/UqFHxy1/+MurUqRNNmjSJbt26xbx5836wflbO0ue/devWceCBB0a3bt3i8ccfz02v7Fg944wz4rzzzovGjRtHixYt4uKLL87rM2nSpNhtt91y74/fX8ZSb7zxRuy+++65MXDyySfH119/nZu+9C+aLrvssmjevHk0bNgwBg4cGN9++22ce+650bhx41hvvfUq7KyuaL2/f6tRo0ZE/PDnWpcuXeK0006LM888M9ZZZ53o3r17RPz4MX7xxRfH7bffHg888EDus+2pp576wXVYmz3yyCOxyy67RMOGDaNJkyax3377xQcffJDX58UXX4ytt946SktLY9ttt42JEyfmTV+8eHGccMIJ0b59+6hTp05ssskmcf311y9zeZdcckk0bdo0ysrK4je/+U3eF/8FCxbEGWecEc2aNYvS0tLYZZddKvyo9UNjpjqe+yVLlsSVV14ZG264YZSUlESbNm3ij3/84zL7Vmbdn3rqqdh+++2jXr160bBhw9h5553j448/joiI1157Lbp27RoNGjSIsrKy6NixY+49/vv7XMOHD49f/vKXERGx/vrrR1FRUXz00UfLPK3Aij6fVrR/9FN25ZVXxumnnx733HNPHHfccSvse/rpp8eAAQNiwYIFy+0za9asOPHEE3Njdffdd4/XXnstN/2DDz6Inj17RvPmzaN+/fqx3XbbxRNPPJE3j3bt2sWgQYPimGOOibKystxfYv7rX/+KXXfdNerUqROtW7eOM844I+8z+MYbb4yNNtooSktLo3nz5nHIIYdExHfvy+PGjYvrr78+N4Y/+uij5a7DEUccEbNmzYq//OUvK9weP7TPnT2F13PPPRdbbbVV7v1g6ZG/2VNVvPzyy7HttttG3bp1Y6eddor33nuvwrL//Oc/R+vWraNu3bpx6KGHxuzZs3PTlixZEgMHDoz11lsvSkpKYquttopHHnkkN31Zf0n+6quv5m2Xpa+hBx98MDbffPMoKSlZK456X1lLP5fXXXfd2GabbeKCCy6IBx54IMaMGZP3l7o/9DqIWPH3wMp+78z2jaj+71Hl5eV5+yER3x15tvT+dttt96NerwsWLIhzzjkn1l133ahXr17ssMMOa+V+xaxZs+KZZ56JK664Irp27Rpt27aN7bffPvr37x8HHHBARCz7tDWzZs3K+7xd+rr9+9//HltssUWUlpbGjjvuGG+++WbuMUtft/fff3/uvbB79+4xbdq0vJpuuumm2GCDDaJ27dqxySabxB133JE3vaioKG666aY44IADol69enHSSSdF165dIyKiUaNGyz0Co1atWnH00Ucv86/Wb7vttthhhx2iQ4cOK/X6WN5vLRHfHQHToUOHKCkpiXbt2lU4onJ5ny3Lss0220Tr1q3j3nvvzbXde++90aZNm9h6663z+lZmf/Df//53HHHEEdG4ceOoV69ebLvttjF+/Pi8Pit6TS7rt6nLLrssjj/++GjQoEG0adMmbrnllrz5TZs2LQ499NBo2LBhNG7cOHr27LnCz77qVJ3vlZX5rL3pppuiR48eUadOnVh//fVj1KhRK1X/D31f+qHnfHn7jEu/J/7pT3+Kli1bRpMmTaJv37554Ur2Pb2oqChuvfXWOOigg6Ju3bqx0UYbxYMPPphX74MPPph7zXft2jVuv/32HzxiLCKid+/eMW7cuLz3iNtuuy169+4dNWvWzOv7Q58tERGXX355NG/ePBo0aBAnnHDCMs8Y8WN+C+JHSrAMffr0ST179lzmtH//+9+pbt266dRTT03vvPNOuu+++9I666yTBgwYkOtz4oknprZt26YnnngivfHGG+mggw5KDRo0SL/97W9zfdq2bZuuvfbalFJKI0eOTGVlZekf//hH+vjjj9P48ePTLbfcklJK6csvv0zrrbdeGjhwYPrss8/SZ599llJKadiwYam8vDw3v4cffjjVqFEjXXTRRentt99Or776arrsssuWu47Zx8+YMSN17do11ahRI3399dcppZSefvrpVFZWloYPH54++OCD9Nhjj6V27dqliy++OKWU0rfffps22WSTtOeee6ZXX301PfPMM2n77bdPEZHuu+++lFJKU6ZMSRGR2rVrl0aPHp0+/PDD9Omnn6Y777wztWzZMtc2evTo1Lhx4zR8+PCUUkpXXXVVat26dXr66afTRx99lJ555pk0YsSIH9xe2W27ePHitNVWW6VddtklvfTSS+mFF15IHTt2TJ07d871HzBgQKpfv346+OCD0xtvvJGefvrp1KJFi3TBBRcsd/vx/y19vdx7772ptLQ0TZs2LaWU0n333Ze+/zb773//O1111VVp4sSJ6YMPPkg33HBDqlGjRho/fnyuT+fOnXOvkzfffDNFRJo8eXJu+tK2SZMmpZTSD46jFdW71Ny5c9Ovf/3rtOGGG6bFixfn2gcNGpSeffbZNGXKlPTggw+m5s2bpyuuuCI3fc8990ynnnpq3ry32GKLdNFFF6WUUvrPf/6TmjZtmvr375/eeeed9Morr6Q999wzde3aNaWU0qeffppq1qyZrrnmmjRlypT0+uuvpyFDhqS5c+dWarvz42Sf/zfeeCO1aNEi7bDDDrm2yo7VsrKydPHFF6f3338/3X777amoqCg99thjKaXv3nt+8YtfpD322CO9+uqrady4cWnrrbfOe3/8+uuvU8uWLXPvPWPHjk3t27dPffr0yau3QYMGqW/fvundd99NQ4cOTRGRunfvnv74xz+m999/Pw0aNCjVqlUr99qrzHp/X2U+1zp37pzq16+fzj333PTuu++md999d6XG+Ny5c9Ohhx6a9t5779xn24IFCyr5LK6dRo0alUaPHp0mTZqUJk6cmPbff//0y1/+Mve+NHfu3NS0adN05JFHpjfffDM99NBDaf31108RkSZOnJhSSmnhwoXpoosuShMmTEgffvhhuvPOO1PdunXTX//619xy+vTpk+rXr58OO+yw9Oabb6aHH344NW3aNO8z74wzzkitWrVK//jHP9Jbb72V+vTpkxo1apS+/PLLlNIPj5nqeu7PO++81KhRozR8+PA0efLk9Mwzz6S//OUvKaX/v39R2XVftGhRKi8vT+ecc06aPHlyevvtt9Pw4cPTxx9/nFJKqUOHDumoo45K77zzTnr//ffT3/72t/Tqq6+mlPL3mb755pv0xBNPpIhIL774Yvrss8/St99+mwYMGJC23HLLXO0/9Pm0vP2jn6Kl7y/nnXdeql+/fnriiSdW2P+f//xnioj0ySefpJYtW6arrroqN628vDwNGzYsd79bt25p//33TxMmTEjvv/9+Ovvss1OTJk1yY/HVV19NN998c3rjjTfS+++/ny688MJUWlqae15T+m6/sKysLP3pT39KkydPzt3q1auXrr322vT++++nZ599Nm299dbp2GOPTSmlNGHChFSjRo00YsSI9NFHH6VXXnklXX/99SmllGbNmpU6deqUTjrppNwY/vbbb5e5rkv3a6655prUvHnz3D72tddem9q2bZvr90P73CmlvM+P2bNnp8aNG6ejjjoqvfXWW+kf//hH2njjjfNeE0u38w477JCeeuqp9NZbb6Vdd9017bTTTrl5DhgwINWrVy/tvvvuaeLEiWncuHFpww03TEceeWSuzzXXXJPKysrS3Xffnd5999103nnnpVq1aqX3338/bzn/+c9/co+ZOHFiiog0ZcqUlNJ3r6FatWqlnXbaKT377LPp3XffTfPmzVvuGPk5WNHn8pZbbpl69OiRu/9Dr4Mf+h5Y2e+d2b6r43vU98f10uVX9fWa0nffv3faaaf09NNPp8mTJ6errroqlZSU5Mbp2mLRokWpfv366cwzz0zz589fZp/s52NK330viYj0z3/+M6X0/1+3m222WXrsscfS66+/nvbbb7/Url27tHDhwpTS/3/dbrvttum5555LL730Utp+++3z3kPuvffeVKtWrTRkyJD03nvvpauvvjrVqFEjPfnkk7k+EZGaNWuWbrvttvTBBx+kjz76KI0ePTpFRHrvvffSZ599lmbNmrXMdXnrrbdSRKRx48bl2ubOnZvq1auXG7cr8/pY3m8tL730UiouLk4DBw5M7733Xho2bFiqU6dO3ufTssbqsix9rV9zzTVpjz32yLXvscce6dprr009e/bM2/evzP7g+uuvn3bdddf0zDPPpEmTJqW//vWv6bnnnkspVe41+f3v3EvXpXHjxmnIkCFp0qRJafDgwam4uDi9++67KaXv9rE222yzdPzxx6fXX389vf322+nII49Mm2yyySrff6/O98rKftY2adIk/eUvf0nvvfdeuvDCC1ONGjXS22+//aNq/KHvSyn98HO+vH3GPn36pLKysvSb3/wmvfPOO+mhhx5KdevWXe57+tL1W2+99dKIESPSpEmT0hlnnJHq16+f20YffvhhqlWrVjrnnHPSu+++m+6+++607rrrVvicz1q6nAMOOCANGjQopZTSvHnzUllZWZo4cWLe/l1lPlv++te/ppKSknTrrbemd999N/3+979PDRo0+FH72t9/L+THE6CwTCt6A7zgggvSJptskpYsWZJrGzJkSKpfv35avHhxmjNnTqpVq1YaOXJkbvqsWbNS3bp1lxugXH311WnjjTfO7axkZd/0UqoYgHTq1Cn17t270us4bNiwFBGpXr16qW7duikiUkSkM844I9dnjz32qBDC3HHHHally5YppZTGjBmTatasmdvRSCmlxx9/fJkBynXXXZc3nw022CAXiCw1aNCg1KlTp5RSSqeffnrafffd87bzUlXZXo899liqUaNGmjp1am760h2xF198MaX03U5G3bp105w5c3J9zj333LwfVFm+779edtxxx3T88cenlCoGKMuy7777prPPPjt3P7szt+WWW6aBAwfm7vfv3z/vefmhcbS8emvUqJHq1auX6tWrlyIitWzZMr388ssrrPWqq65KHTt2zN3/61//mho1apT78vLyyy+noqKi3I8FgwYNSnvttVfePKZNm5b7svDyyy+niEgfffTRCpdL9fr+819SUpIiIhUXF6dRo0at8HHLGqu77LJLXp/tttsu/e53v0sppfToo4+mmjVrpk8++SQ3fcyYMXnvj7fccktq1KhR7ge1lFL6+9//noqLi9P06dNz9bZt2zYv3Ntkk03Srrvumrv/7bffpnr16qW77767Uuu99HbIIYeklH74c23p+m699dZ581zZMb6iz1pS+vzzz1NEpDfeeCOllNKf//zn1KRJk/Tf//431+emm276wS8Gffv2Tb169crd79OnT2rcuHHej5c33XRT7vn++uuvU61atdJdd92Vm75w4cLUqlWrdOWVV6aUfnjMVMdzP2fOnFRSUpILTLIq86Xo++v+5ZdfpohITz311DL7NmjQYLnh+/9r797jerz//4E/Or3r3VlCstQtlByKkA4b81l9spkJS6tMkZwmp7H48CmMsYmNbRifDmzOYvuMOQ1Zn7dymFXMW4XQhjGHLGJTr+8ffu/r1/tQvUuJedxvN7eb9/t9XV2v67pep+t6Xdfrqdnn0rw5LITQGkCpqX2qqn/0LIqKihIymUwAEPv3769x+co33FeuXCns7Oykm2eVL7AzMzOFtbW11k3CNm3aiC+++KLKv9+xY0fx6aefSp+dnZ1FSEiI2jIxMTFi1KhRat9lZmYKQ0NDUVZWJtLT04W1tbVa37Ayzf5KVVTL3b9/Xzg7O0t9Gs0BlJr63EKo32hesWKFVn2wevVqnQMolQe0du7cKQBI6yUmJgojIyPxyy+/SMvs2rVLGBoaSv17R0dHMX/+fLW09ejRQ3qIRN8BFADSoCRVXw+GhYUJDw8PIYR+5aCm68C6Xnc+iesoXQMotS2vFy9eFEZGRmp9LiEelasZM2bolY5nydatW0WTJk2EmZmZ8Pf3FzNmzBC5ubnS77UZQNm4caO0zI0bN4RcLpcePFCV2+zsbGkZpVIpAEgPFfn7+4vY2Fi19IWGhorXXntN+gxATJo0SW0ZXfVGVXx9fdUGGJKTk6U8V9/lQyUiIkIEBQWpfTdt2jTRoUMHtfU086ouqrJ+7do1YWpqKi5cuCAuXLggzMzMxPXr17UGUDTp6g9aWVlJN7w16VMmdQ2gDB06VPpcUVEhmjdvLlasWCGEeNQeafb7Hjx4IORyudizZ0+Nx+Bx1GddqW9bO2bMGLVlevbsKcaOHVunNNZ0vaSL5jmvqs+ouk6s/BBHaGioCAsLkz7rGkCZNWuW9Lm0tFQAELt27RJCCBEfHy86deqktp2ZM2fqPYDy9ddfizZt2oiKigqxZs0a6fqxcv9On7bFz89P62HVnj171qmvzQGU+sEpvKjWlEol/Pz81F7vDAgIQGlpKX755RecP38ef/31F3x8fKTfbWxs4O7uXuXfDA0NRVlZGVxdXREbG4vt27fXei7HnJwcvPLKK7Vax8rKCjk5OTh+/DgWL14Mb29vtakxcnNzMXfuXFhaWkr/YmNjceXKFdy7dw/5+flwcnKSXr8GoLbflXXv3l36/927d3Hu3DnExMSo/e158+ZJrypGR0cjJycH7u7umDBhAvbu3SutX5vjpVQq4eTkBCcnJ+m7Dh06wNbWFkqlUvrOxcVFbR7Qli1b4tq1a/oeSvp/PvzwQ6xZs0bt2KqUl5fj/fffR+fOnWFnZwdLS0vs2bOn2ikcIiMjsX79egCPphzYsGEDIiMjAeiXj6rSp08f5OTkICcnB0ePHkVwcDBeffVVaSoXANi0aRMCAgLg4OAAS0tLzJo1Sy2tISEhMDIywvbt2wE8es29T58+UvDL3NxcHDx4UC1t7du3B/BoyhEvLy+88sor6Ny5M0JDQ7F69erHjiFD+lGd/yNHjiAqKgrDhw/H4MGDpd/1zauenp5qnyvXG6q6x9HRUfrdz89PbXmlUgkvLy+1OWEDAgJQUVGhNsVKx44dYWj4/7ssLVq0kKYQAgAjIyM0bdq0xjqrcr7PycnBsmXLpHRU166pdOvWTe3vMY/Xr8LCQoSHh8PV1RXW1tZSXaLKd0qlUppmQ0UzTwHA559/jm7duqFZs2awtLTEqlWrtPKul5eX2nzIfn5+KC0tRXFxMc6dO4e//voLAQEB0u8mJibw8fGR6vaa8kx9nHulUokHDx7Uqm9T3b7b2dkhOjoawcHB6N+/vzQPv8qUKVMwcuRIBAYGYuHChTW2I9WpTftUuX/0LPP09ISLiwsSExPVpiHs2LGjtP+6AqDHxMSgadOm+PDDD7V+y83NRWlpKZo2bap2HIuKiqTjWFpaiqlTp8LDwwO2trawtLSEUqnUyvOaxzk3NxdpaWlqfzc4OBgVFRUoKipCUFAQnJ2d4erqirfffhvr1q3DvXv36nx8TE1NMXfuXCQlJalN21E5PdX1uTXl5+dr1QdV9cErt1UtW7YEALX2onXr1mjVqpX02c/PT2qH7ty5g8uXL6vVB8Cj8q6rr1cdmUym1W6SbkIIqX7VpxzU5jrwWbiOqm15PXnyJMrLy+Hm5qa2zKFDhx6rLn9aDR48GJcvX8Z///tf9O3bFxkZGfD29q5TgObK/Qg7Ozu4u7urnVtjY2P06NFD+ty+fXu1869UKvWqHx6nrRsxYgS2bt0qTUGVkpKC0NBQWFlZ1Xv5UKlqvwoLC1FeXl6n/WrWrBn69euHtLQ0pKamol+/frC3t9darqb+YE5ODrp27Qo7O7sqt1WXMlm5flZN9a5aJzc3F2fPnoWVlZV0jO3s7HD//v1GLWO1rSv1bWs1+9d+fn61bvNUarpeAmo+5yq68lvHjh2lKZmB2p9rCwsLWFtbS+vk5+erlXmg6v6FLv369UNpaSl++OEHpKSkYMSIEVrL6NO2KJVKrencK5+Xx7kXRHVjXPMiRA3PyckJ+fn5+P7777Fv3z6MGzcOixYtwqFDh2BiYqLX35DL5bXerqGhIdq2bQsA8PDwwLlz5zB27Fhp3tLS0lLMmTMHgwYN0lq38gWbPirfIFRdWK9evVqrUlRV/t7e3igqKsKuXbvw/fffY8iQIQgMDMTWrVvr5Xhp0lzPwMCAwS3roFevXggODsaMGTO05rJdtGgRli5dik8++QSdO3eGhYUFJk2aVG3AvfDwcMTHx+PEiRMoKytDcXExwsLCAOiXj6piYWEh5X3g0dyZNjY2WL16NebNm4esrCxERkZizpw5CA4Oho2NDTZu3Kg2961MJsOwYcOQmpqKQYMGYf369Wrz7ZeWlqJ///46bwq1bNkSRkZG2LdvHw4fPoy9e/fi008/xcyZM3HkyJE6B/Ym/VQ+/ykpKfDy8kJycrIUiFLfvPqk6g1d26nLtjXzfW1pBv9jHq9f/fv3h7OzM1avXg1HR0dUVFSgU6dOtQqgu3HjRkydOhWLFy+Gn58frKyssGjRIq15sRtafZz72vZr9Nn31NRUTJgwAbt378amTZswa9Ys7Nu3D76+vpg9ezYiIiKwc+dO7Nq1C4mJidi4cWON8eR0qU379HcJqtmqVSts3boVffr0Qd++fbFr1y5YWVnhu+++k+bi1nVOjY2NMX/+fERHR2P8+PFqv5WWlqJly5Y64xioYtJMnToV+/btQ1JSEtq2bQu5XI4333xTq9zoqr9Gjx6tFvtBpXXr1pDJZDhx4gQyMjKwd+9eJCQkYPbs2Th27JhWDEJ9DR06FElJSZg3b550c6Ryeuqrz62pcnuhutFUn22VaoBfCCF9pyu4rVwuVxt0paoplUqprtSnHNSmvnwWrqNqW17z8vJgZGSEH3/8UauOtbS0rHM6nmZmZmYICgpCUFAQ/v3vf2PkyJFITExEdHS03mXySXqctu6tt97C5MmTsXnzZvTq1QsKhUKKu1nf5aO2artfI0aMkNq6zz//XOcyNfUH9dmfupTJ6tYpLS1Ft27ddMZqa9asWY3paSi1rSsbsq2tSk3XS4D+1wC68lt9n+vHZWxsjLfffhuJiYk4cuSI9LBpfXuce0FUNxxAoVrz8PBAenq62mi3QqGAlZUVXnjhBTRp0gQmJiY4duwYWrduDQAoKSlBQUEBevXqVeXflcvl6N+/P/r374933nkH7du3x8mTJ+Ht7Q2ZTKb2pIMunp6e2L9/f40BO6szffp0tGnTBpMnT4a3tze8vb2Rn59f5Q03d3d3FBcX47fffkOLFi0AQCvIrC4tWrSAo6Mjzp8/L71NoIu1tTXCwsIQFhaGN998E3379sXNmzdhZ2dX7fGqzMPDA8XFxSguLpZGuE+fPo3bt2+jQ4cO+h4aqoWFCxeiS5cuWm9dKRQKDBgwAEOHDgXw6OK9oKCg2vPwwgsvoHfv3li3bh3KysoQFBSE5s2bA9A/H+nDwMAAhoaGKCsrA/AoMKuzszNmzpwpLVP57RSVkSNHolOnTli+fDkePnyo1hnz9vZGeno6XFxctIKmVd5uQEAAAgICkJCQAGdnZ2zfvh1Tpkx5rP0h/RkaGuJf//oXpkyZgoiICMjl8jrlVU2quufKlStS5zg7O1trmbS0NNy9e1fqECsUChgaGlb71mJ9q6ldq8rj5nF92rbnxY0bN5Cfn4/Vq1fjpZdeAvAoYG5lHh4e+PLLL3H//n3pIk8zTykUCvj7+2PcuHHSd7qewsrNzUVZWZl0EZ6dnQ1LS0s4OTnB3t4eMpkMCoUCzs7OAB7deDl27JgUcFSfPPO4575du3aQy+XYv38/Ro4cWeMx1Hffu3btiq5du2LGjBnw8/PD+vXr4evrCwBwc3ODm5sbJk+ejPDwcKSmptZpAKU+26dnibOzMw4dOiQNouzevVvKQ9UJDQ3FokWLMGfOHLXvvb29cfXqVRgbG2sNOKgoFApER0dL56m0tFSvoLbe3t44ffp0tYPKxsbGCAwMRGBgIBITE2Fra4sDBw5g0KBBdaq/DA0NsWDBAgwaNAhjx47VSk91fW5N7u7u+Oqrr/DgwQOYmpoC0K8PrsulS5dw+fJl6Y3J7OxsqR2ytraGo6MjFAoFevfuLa2jUCikJ1JVN8+uXLmCJk2aAIBWIHvS34EDB3Dy5ElMnjwZgH7loLbXgc/adVRN5bVr164oLy/HtWvXpDb0edOhQwd8/fXXANTLpCpAeVVlMjs7W7pncevWLRQUFMDDw0P6/eHDhzh+/LhU3vPz83H79m1pGQ8PDygUCkRFRUnrKBSKGvOHTCYDAL3qUSsrK4SGhiIlJQXnzp2Dm5ubdJ7ro3zoqs9V+1WZQqGAm5vbY92c7du3L/78808YGBggODhY63d9+oOenp74z3/+I90XeRK8vb2xadMmNG/eHNbW1k9kmzWpS12pb1ubnZ2NYcOGqX1WlaXaqul6SZ9z/iS5u7vju+++U/uutv2LESNGICkpCWFhYVK/oDJ92hYPDw8cOXJE6zyoPK997cbEKbyoSiUlJWpTneTk5KC4uBjjxo1DcXEx4uLicObMGXzzzTdITEzElClTYGhoCCsrK0RFRWHatGk4ePAgfv75Z8TExMDQ0LDKp67S0tKQnJyMU6dO4fz58/jqq68gl8uli04XFxf88MMP+PXXX3W+9g8AiYmJ2LBhAxITE6FUKnHy5Emdo9zVcXJywsCBA5GQkAAASEhIwNq1azFnzhz8/PPPUCqV2LhxI2bNmgUACAoKQps2bRAVFYW8vDwoFArpt5qeMJszZw4WLFiAZcuWoaCgACdPnkRqaiqWLFkCAFiyZAk2bNiAM2fOoKCgAFu2bIGDgwNsbW1rPF6VBQYGonPnzoiMjMSJEydw9OhRDBs2DL179/7bTJvxtFEdb9X0QCrt2rWTnkhWKpUYPXo0fvvttxr/XmRkJDZu3IgtW7ZoNY415aOqPHjwAFevXsXVq1ehVCoRFxcnPR2iSuulS5ewceNGnDt3DsuWLdP59ISHhwd8fX0RHx+P8PBwtSeC3nnnHdy8eRPh4eE4duwYzp07hz179mD48OEoLy/HkSNH8MEHH+D48eO4dOkStm3bhuvXr6tdtNCTERoaCiMjI+lJsLrm1coCAwPh5uaGqKgo5ObmIjMzU21ADniUt83MzBAVFYVTp07h4MGDiIuLw9tvvy0NSj8JNbVrVXncPO7i4oK8vDzk5+fj999/b/SnIxtTkyZN0LRpU6xatQpnz57FgQMHtAZSIyIiYGBggNjYWJw+fRrfffcdkpKS1JZp164djh8/jj179qCgoAD//ve/dV70/Pnnn4iJiZH+TmJiIsaPHw9DQ0NYWFhg7NixmDZtGnbv3o3Tp08jNjYW9+7dk97SqinP1Me5NzMzQ3x8PN577z2sXbsW586dQ3Z2NpKTk3Uew5r2vaioCDNmzEBWVhYuXryIvXv3orCwEB4eHigrK8P48eORkZGBixcvQqFQ4NixY49VH9e1fXrWOTk5ISMjA9euXUNwcDDu3Lmj13oLFy5ESkoK7t69K30XGBgIPz8/hISEYO/evbhw4QIOHz6MmTNn4vjx4wAenfdt27YhJycHubm5iIiI0Ospyvj4eBw+fBjjx49HTk4OCgsL8c0330hPBu/YsQPLli1DTk4OLl68iLVr16KiokIa3HZxccGRI0dw4cIF/P7773o/udmvXz/07NkTX3zxhdr3NfW5Nan2c9SoUVAqldizZ49UH9T2LQ9VO6RqqyZMmIAhQ4ZIU/ROmzYNH374ITZt2oT8/HxMnz4dOTk5mDhxIgCgbdu2cHJywuzZs1FYWIidO3eqvbFLVVP1R3/99VecOHECH3zwAQYMGIDXX39dummkTzmozXXgs3gdVVN5dXNzQ2RkJIYNG4Zt27ahqKgIR48exYIFC7Bz584nls4n4caNG/jHP/6Br776Cnl5eSgqKsKWLVvw0UcfYcCAAQAeDZD5+vpi4cKFUCqVOHToUJV1ydy5c7F//36cOnUK0dHRsLe3R0hIiPS7iYkJ4uLicOTIEfz444+Ijo6Gr6+vNKAybdo0pKWlYcWKFSgsLMSSJUuwbds2TJ06tdr9cHZ2hoGBAXbs2IHr16+rTf2oS0xMDA4fPoyVK1eqTQlUH+VD172Wd999F/v378f777+PgoICrFmzBp999lmN+1UTIyMjKJVKnD59WudAjD79wfDwcDg4OCAkJAQKhQLnz59Heno6srKyHitt1YmMjIS9vT0GDBiAzMxMFBUVISMjAxMmTFCb7reh1FddqW9bu2XLFqSkpKCgoACJiYk4evSo1luymqq6f1jT9ZI+5/xJGj16NM6cOYP4+HgUFBRg8+bN0vSA+vYvPDw88PvvvyM1NVXn7/q0LRMnTkRKSgpSU1Ol8/Dzzz+r/Z3nta/daBov/Ao9zaKioqSg6pX/xcTECCGEyMjIED169BAymUw4ODiI+Ph48ddff0nr37lzR0RERAhzc3Ph4OAglixZInx8fMT06dOlZSoHc9q+fbvo2bOnsLa2FhYWFsLX11ct4GNWVpbw9PSUAh4LoR3QVAgh0tPTRZcuXYRMJhP29vZi0KBBVe6jrvVV20KlwHC7d+8W/v7+Qi6XC2tra+Hj4yNWrVolLa9UKkVAQICQyWSiffv24ttvvxUAxO7du4UQ1QduWrdunZTeJk2aiF69eolt27YJIR4FV+7SpYuwsLAQ1tbW4pVXXhEnTpzQ63hpBsq6ePGieOONN4SFhYWwsrISoaGhUoBmIbQDvwqhHdyTqqYraFpRUZEUUFblxo0bYsCAAcLS0lI0b95czJo1SwwbNkxtXV1BWW/duiVMTU2Fubm5+OOPP7S2X10+qiq9lcu1lZWV6NGjh1YQ8WnTpommTZsKS0tLERYWJj7++GOdZSY5OVkt4FllBQUFYuDAgcLW1lbI5XLRvn17MWnSJFFRUSFOnz4tgoODRbNmzYSpqalwc3NTC3pLDaOqIH8LFiwQzZo1E6WlpXXOq5pBIPPz88WLL74oZDKZcHNzE7t379YKlpqXlyf69OkjzMzMhJ2dnYiNjVXL57rSq2vbugJg6rPfKjW1a1UFTH6cPH7t2jURFBQkLC0t1QKbPq/27dsnPDw8hKmpqfD09BQZGRla+SUrK0t4eXkJmUwmunTpItLT09Xa2Pv374vo6GhhY2MjbG1txdixY8X06dPV2jhVXkhISJDquNjYWLWgm2VlZSIuLk7Y29sLU1NTERAQoFXHVZdn6uvcl5eXi3nz5glnZ2dhYmIiWrduLQX/1Oxf1LTvV69eFSEhIaJly5ZCJpMJZ2dnkZCQIMrLy8WDBw/EW2+9JZycnIRMJhOOjo5i/PjxUqDtugSRF6L69unvFNhSV/3yyy+/iHbt2glfX19RUlKi9ltVwYP/+c9/CgBSkFEhHvWp4+LihKOjozAxMRFOTk4iMjJSCjxaVFQk+vTpI+RyuXBychKfffaZzuC4uurHo0ePSvnQwsJCeHp6SsHSMzMzRe/evUWTJk2EXC4Xnp6eUmBlIR7V776+vkIul2vlhcp01Z2HDx8WALT6mTX1uTXrA4VCITw9PYVMJhPdunUT69evFwDEmTNnqjzOmnlXlW+XL18uHB0dhZmZmXjzzTfFzZs3pXXKy8vF7NmzRatWrYSJiYnw8vKSgs2q/O9//xOdO3cWZmZm4qWXXhJbtmzRCiKvqw/1PKvcHzU2NhbNmjUTgYGBIiUlRZSXl6stW1M5EKL668DaXHc+6esozXxdl/IqhBB//vmnSEhIEC4uLsLExES0bNlSDBw4UOTl5emVjmfF/fv3xfTp04W3t7ewsbER5ubmwt3dXcyaNUvcu3dPWu706dPCz89PyOVy0aVLF7F3716dQeS//fZb0bFjRyGTyYSPj49aMHpVuU1PTxeurq7C1NRUBAYGiosXL6qlafny5cLV1VWYmJgINzc3sXbtWrXfNc+xyty5c4WDg4MwMDCoNoi6iru7uzAyMhKXL19W+/5xy4euey1CCLF161bRoUMHqf+xaNEite3W1PdWqakPrnn9oE9/8MKFC2Lw4MHC2tpamJubi+7du0v3b/Qpk/q0k15eXiIxMVH6fOXKFTFs2DCpb+jq6ipiY2O12vj6Vt91pT5t7eeffy6CgoKEqampcHFxUWv/a0qjrvuH1V0vCVHzOa+qz6grb02cOFH07t1b+qwriLxmeawc4F0IIb755hvRtm1bYWpqKl5++WWxYsUKAUDqF+tSU3nQ3EZNbYsQQsyfP1/Y29sLS0tLERUVJd57773ntq/9NDAQotLEkEQN5O7du2jVqhUWL14sPb35d6VQKPDiiy/i7NmzaNOmTWMnh6jBvf/++9iyZQvy8vIaOylERET0nFq3bh2GDx+OkpKSBp3zn4iefRkZGejTpw9u3bpVZVyntLQ0TJo0Cbdv336iaSNqTAYGBti+fbvam1jPu/nz52PlypUoLi5u7KRQI2IMFGoQP/30E86cOQMfHx+UlJRg7ty5ACC9Vvt3sn37dlhaWqJdu3Y4e/YsJk6ciICAAA6e0N+eap71zz77DPPmzWvs5BAREdFzZO3atXB1dUWrVq2Qm5uL+Ph4DBkyhIMnREREVGfLly9Hjx490LRpUygUCixatKjGKczo748DKNRgkpKSkJ+fD5lMhm7duiEzMxP29vaNnax698cffyA+Ph6XLl2Cvb09AgMDOe8xPRfGjx+PDRs2ICQkRG0uXiIiIqKGdvXqVSQkJODq1ato2bIlQkNDMX/+/MZOFhERET3DCgsLMW/ePNy8eROtW7fGu+++ixkzZjR2sqiRcQovIiIiIiIiIiIiIiIiDYaNnQAiIiIiIiIiIiIiIqKnDQdQiIiIiIiIiIiIiIiINHAAhYiIiIiIiIiIiIiISAMHUIiIiIiIiIiIiIiIiDRwAIWIiIiIiIiIiIiIiEgDB1CIiIiIiKhRZGRkwMDAALdv335qtuXi4oJPPvmkwdNDRERERERPPw6gEBERERFRg8rKyoKRkRH69evXaGnw9/fHlStXYGNjAwBIS0uDra1to6WHiIiIiIiefhxAISIiIiKiBpWcnIy4uDj88MMPuHz58hPf/l9//QWZTAYHBwcYGBg88e0TEREREdGziQMoRERERETUYEpLS7Fp0yaMHTsW/fr1Q1paWrXLr169Gk5OTjA3N8fAgQOxZMkSrTdFVqxYgTZt2kAmk8Hd3R1ffvml2u8GBgZYsWIF3njjDVhYWGD+/PlqU3hlZGRg+PDhKCkpgYGBAQwMDDB79mxp/Xv37mHEiBGwsrJC69atsWrVKum3CxcuwMDAAJs3b8ZLL70EuVyOHj16oKCgAMeOHUP37t1haWmJV199FdevX5fWy8jIgI+PDywsLGBra4uAgABcvHixzseViIiIiIgaHgdQiIiIiIiowWzevBnt27eHu7s7hg4dipSUFAghdC6rUCgwZswYTJw4ETk5OQgKCsL8+fPVltm+fTsmTpyId999F6dOncLo0aMxfPhwHDx4UG252bNnY+DAgTh58iRGjBih9pu/vz8++eQTWFtb48qVK7hy5QqmTp0q/b548WJ0794dP/30E8aNG4exY8ciPz9f7W8kJiZi1qxZOHHiBIyNjREREYH33nsPS5cuRWZmJs6ePYuEhAQAwMOHDxESEoLevXsjLy8PWVlZGDVqFN+GISIiIiJ6yhk3dgKIiIiIiOjvKzk5GUOHDgUA9O3bFyUlJTh06BBefvllrWU//fRTvPrqq9JghpubGw4fPowdO3ZIyyQlJSE6Ohrjxo0DAEyZMgXZ2dlISkpCnz59pOUiIiIwfPhw6fP58+el/8tkMtjY2MDAwAAODg5a6Xjttdekvx8fH4+PP/4YBw8ehLu7u7TM1KlTERwcDACYOHEiwsPDsX//fgQEBAAAYmJipLdt7ty5g5KSErz++uto06YNAMDDw0PPI0hERERERI2Fb6AQEREREVGDyM/Px9GjRxEeHg4AMDY2RlhYGJKTk6tc3sfHR+07zc9KpVIapFAJCAiAUqlU+6579+51Trenp6f0f9Ugy7Vr16pcpkWLFgCAzp07q32nWsfOzg7R0dEIDg5G//79sXTpUly5cqXO6SMiIiIioieDAyhERERERNQgkpOT8fDhQzg6OsLY2BjGxsZYsWIF0tPTUVJS0qDbtrCwqPO6JiYmap8NDAxQUVFR5TKqqbg0v6u8TmpqKrKysuDv749NmzbBzc0N2dnZdU4jERERERE1PA6gEBERERFRvXv48CHWrl2LxYsXIycnR/qXm5sLR0dHbNiwQWsdd3d3HDt2TO07zc8eHh5QKBRq3ykUCnTo0KFW6ZPJZCgvL6/VOo+ra9eumDFjBg4fPoxOnTph/fr1T3T7RERERERUO4yBQkRERERE9W7Hjh24desWYmJiYGNjo/bb4MGDkZycjEWLFql9HxcXh169emHJkiXo378/Dhw4gF27dqkFW582bRqGDBmCrl27IjAwEN9++y22bduG77//vlbpc3FxQWlpKfbv3w8vLy+Ym5vD3Ny87jtcjaKiIqxatQpvvPEGHB0dkZ+fj8LCQgwbNqxBtkdERERERPWDb6AQEREREVG9S05ORmBgoNbgCfBoAOX48ePIy8tT+z4gIAArV67EkiVL4OXlhd27d2Py5MkwMzOTlgkJCcHSpUuRlJSEjh074osvvkBqaqrOoPTV8ff3x5gxYxAWFoZmzZrho48+qtN+6sPc3BxnzpzB4MGD4ebmhlGjRuGdd97B6NGjG2ybRERERET0+AyEEKKxE0FERERERKRLbGwszpw5g8zMzMZOChERERERPWc4hRcRERERET01kpKSEBQUBAsLC+zatQtr1qzB8uXLGztZRERERET0HOIbKERERERE9NQYMmQIMjIy8Mcff8DV1RVxcXEYM2ZMYyeLiIiIiIieQxxAISIiIiIiIiIiIiIi0sAg8kRERERERERERERERBo4gEJERERERERERERERKSBAyhEREREREREREREREQaOIBCRERERERERERERESkgQMoREREREREREREREREGjiAQkREREREREREREREpIEDKERERERERERERERERBo4gEJERERERERERERERKTh/wCmUsiOqzVzDQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}