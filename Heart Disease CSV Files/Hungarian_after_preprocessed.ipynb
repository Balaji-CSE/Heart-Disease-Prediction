{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**DATA COLLECTION**"
      ],
      "metadata": {
        "id": "wzjM7uiJJmtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df = pd.read_csv('hungarian_ds.csv')\n",
        "\n",
        "# Replace '?' with NaN for easier handling of missing values\n",
        "df.replace('?', np.nan, inplace=True)\n"
      ],
      "metadata": {
        "id": "33x38vc_I5U4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CHECKING FOR MISSING VALUE**"
      ],
      "metadata": {
        "id": "clpXl4cwJwHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To check any feature has missing values or not!!\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0t51oXJI5IV",
        "outputId": "a44dcc2c-6d9b-44c2-c999-6c60356152de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age           0\n",
              "sex           0\n",
              "cp            0\n",
              "trestbps      1\n",
              "chol         23\n",
              "fbs           8\n",
              "restecg       1\n",
              "thalach       1\n",
              "exang         1\n",
              "oldpeak       0\n",
              "slope       190\n",
              "ca          291\n",
              "thal        266\n",
              "target        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA PRE-PROCESSING / DATA CLEANING**"
      ],
      "metadata": {
        "id": "Sn9phwOlJ1Le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace '?' with NaN for easier handling of missing values\n",
        "df.replace('?', np.nan, inplace=True)\n",
        "\n",
        "# Handle missing values (NaN)\n",
        "# Mean imputation for numeric columns in this example\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df[['trestbps', 'chol', 'ca', 'thalach']] = imputer.fit_transform(df[['trestbps', 'chol', 'ca', 'thalach']])\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']\n",
        "for col in categorical_cols:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "# Split the data into features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n"
      ],
      "metadata": {
        "id": "53ZV1wDMGGQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTING MODULES SECTION**"
      ],
      "metadata": {
        "id": "bXrzR1sTKOi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from mlxtend.classifier import StackingCVClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,roc_curve, roc_auc_score\n",
        "import statistics"
      ],
      "metadata": {
        "id": "2UDBruAsMpsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-NEAREST NEIGHBOR**"
      ],
      "metadata": {
        "id": "pwqsTKcGKT8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "m1 = 'knn classifier'\n",
        "k = 10\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "total_accuracy = 0\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=9)\n",
        "    knn.fit(X_train_fold, y_train_fold)\n",
        "    knnpred = knn.predict(X_test_fold)\n",
        "    cm = confusion_matrix(y_test_fold, knnpred)\n",
        "    fold_accuracy = accuracy_score(y_test_fold, knnpred) * 100\n",
        "    print('Accuracy for this fold:', fold_accuracy)\n",
        "    total_accuracy += fold_accuracy\n",
        "    print(\"Confusion Matrix for Fold:\")\n",
        "    print(cm)\n",
        "\n",
        "knnaccuracy = total_accuracy / k\n",
        "print(\"Mean Accuracy =\", knnaccuracy)"
      ],
      "metadata": {
        "id": "7uaQueZfLB9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4920cbea-0235-4b6c-df15-121acc4758dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for this fold: 66.66666666666666\n",
            "Confusion Matrix for Fold:\n",
            "[[16  4]\n",
            " [ 6  4]]\n",
            "Accuracy for this fold: 53.333333333333336\n",
            "Confusion Matrix for Fold:\n",
            "[[12  7]\n",
            " [ 7  4]]\n",
            "Accuracy for this fold: 73.33333333333333\n",
            "Confusion Matrix for Fold:\n",
            "[[19  4]\n",
            " [ 4  3]]\n",
            "Accuracy for this fold: 56.666666666666664\n",
            "Confusion Matrix for Fold:\n",
            "[[15  4]\n",
            " [ 9  2]]\n",
            "Accuracy for this fold: 55.172413793103445\n",
            "Confusion Matrix for Fold:\n",
            "[[12  7]\n",
            " [ 6  4]]\n",
            "Accuracy for this fold: 58.620689655172406\n",
            "Confusion Matrix for Fold:\n",
            "[[14  4]\n",
            " [ 8  3]]\n",
            "Accuracy for this fold: 72.41379310344827\n",
            "Confusion Matrix for Fold:\n",
            "[[16  1]\n",
            " [ 7  5]]\n",
            "Accuracy for this fold: 41.37931034482759\n",
            "Confusion Matrix for Fold:\n",
            "[[10  3]\n",
            " [14  2]]\n",
            "Accuracy for this fold: 82.75862068965517\n",
            "Confusion Matrix for Fold:\n",
            "[[19  2]\n",
            " [ 3  5]]\n",
            "Accuracy for this fold: 72.41379310344827\n",
            "Confusion Matrix for Fold:\n",
            "[[17  2]\n",
            " [ 6  4]]\n",
            "Mean Accuracy = 63.2758620689655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOGISTIC REGRESSION**"
      ],
      "metadata": {
        "id": "1VgnvD6DKcWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "m2 = 'lr classifier'\n",
        "k = 10\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=23)\n",
        "\n",
        "total_accuracy = 0\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    lr =LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000)\n",
        "\n",
        "    lr.fit(X_train_fold,y_train_fold)\n",
        "    lrpred = lr.predict(X_test_fold)\n",
        "    cm = confusion_matrix(y_test_fold, lrpred)\n",
        "    fold_accuracy = accuracy_score(y_test_fold, lrpred) * 100\n",
        "    print('Accuracy for this fold:', fold_accuracy)\n",
        "    total_accuracy += fold_accuracy\n",
        "    print(\"Confusion Matrix for Fold:\")\n",
        "    print(cm)\n",
        "\n",
        "lraccuracy = total_accuracy / k\n",
        "print(\"Mean Accuracy =\", lraccuracy)"
      ],
      "metadata": {
        "id": "GfSI10J1LCL4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08ef362d-69ea-40e8-90c5-883e6f66ebfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for this fold: 73.33333333333333\n",
            "Confusion Matrix for Fold:\n",
            "[[12  2]\n",
            " [ 6 10]]\n",
            "Accuracy for this fold: 90.0\n",
            "Confusion Matrix for Fold:\n",
            "[[19  2]\n",
            " [ 1  8]]\n",
            "Accuracy for this fold: 90.0\n",
            "Confusion Matrix for Fold:\n",
            "[[22  1]\n",
            " [ 2  5]]\n",
            "Accuracy for this fold: 70.0\n",
            "Confusion Matrix for Fold:\n",
            "[[18  5]\n",
            " [ 4  3]]\n",
            "Accuracy for this fold: 86.20689655172413\n",
            "Confusion Matrix for Fold:\n",
            "[[17  2]\n",
            " [ 2  8]]\n",
            "Accuracy for this fold: 79.3103448275862\n",
            "Confusion Matrix for Fold:\n",
            "[[ 9  3]\n",
            " [ 3 14]]\n",
            "Accuracy for this fold: 89.65517241379311\n",
            "Confusion Matrix for Fold:\n",
            "[[20  0]\n",
            " [ 3  6]]\n",
            "Accuracy for this fold: 79.3103448275862\n",
            "Confusion Matrix for Fold:\n",
            "[[15  1]\n",
            " [ 5  8]]\n",
            "Accuracy for this fold: 75.86206896551724\n",
            "Confusion Matrix for Fold:\n",
            "[[18  2]\n",
            " [ 5  4]]\n",
            "Accuracy for this fold: 86.20689655172413\n",
            "Confusion Matrix for Fold:\n",
            "[[18  2]\n",
            " [ 2  7]]\n",
            "Mean Accuracy = 81.98850574712642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM Classifier**"
      ],
      "metadata": {
        "id": "3Nf9vCP_K-Pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM\n",
        "m3 = 'svm classifier'\n",
        "k = 10\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=23)\n",
        "\n",
        "total_accuracy = 0\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    Svm = SVC(kernel = 'linear',C=2,probability=True)\n",
        "    Svm.fit(X_train_fold,y_train_fold)\n",
        "    Svmpred = Svm.predict(X_test_fold)\n",
        "    cm = confusion_matrix(y_test_fold, Svmpred)\n",
        "    fold_accuracy = accuracy_score(y_test_fold, Svmpred) * 100\n",
        "    print('Accuracy for this fold:', fold_accuracy)\n",
        "    total_accuracy += fold_accuracy\n",
        "    print(\"Confusion Matrix for Fold:\")\n",
        "    print(cm)\n",
        "\n",
        "svmaccuracy = total_accuracy / k\n",
        "print(\"Mean Accuracy =\", svmaccuracy)"
      ],
      "metadata": {
        "id": "43gEh1XGTgeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f52b92da-25df-4c66-cfe7-0baf0ac6ed49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for this fold: 66.66666666666666\n",
            "Confusion Matrix for Fold:\n",
            "[[11  3]\n",
            " [ 7  9]]\n",
            "Accuracy for this fold: 86.66666666666667\n",
            "Confusion Matrix for Fold:\n",
            "[[19  2]\n",
            " [ 2  7]]\n",
            "Accuracy for this fold: 93.33333333333333\n",
            "Confusion Matrix for Fold:\n",
            "[[23  0]\n",
            " [ 2  5]]\n",
            "Accuracy for this fold: 73.33333333333333\n",
            "Confusion Matrix for Fold:\n",
            "[[18  5]\n",
            " [ 3  4]]\n",
            "Accuracy for this fold: 86.20689655172413\n",
            "Confusion Matrix for Fold:\n",
            "[[18  1]\n",
            " [ 3  7]]\n",
            "Accuracy for this fold: 82.75862068965517\n",
            "Confusion Matrix for Fold:\n",
            "[[10  2]\n",
            " [ 3 14]]\n",
            "Accuracy for this fold: 93.10344827586206\n",
            "Confusion Matrix for Fold:\n",
            "[[20  0]\n",
            " [ 2  7]]\n",
            "Accuracy for this fold: 82.75862068965517\n",
            "Confusion Matrix for Fold:\n",
            "[[16  0]\n",
            " [ 5  8]]\n",
            "Accuracy for this fold: 72.41379310344827\n",
            "Confusion Matrix for Fold:\n",
            "[[17  3]\n",
            " [ 5  4]]\n",
            "Accuracy for this fold: 86.20689655172413\n",
            "Confusion Matrix for Fold:\n",
            "[[19  1]\n",
            " [ 3  6]]\n",
            "Mean Accuracy = 82.34482758620689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DECISION TREE**"
      ],
      "metadata": {
        "id": "Zx-UmCk0LbYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DT\n",
        "m4 = 'decision tree'\n",
        "k = 10\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=23)\n",
        "\n",
        "total_accuracy = 0\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    dt = DecisionTreeClassifier(criterion='entropy',random_state = 0,max_depth=6)\n",
        "    dt.fit(X_train_fold,y_train_fold)\n",
        "    dtpred = dt.predict(X_test_fold)\n",
        "    cm = confusion_matrix(y_test_fold, dtpred)\n",
        "    fold_accuracy = accuracy_score(y_test_fold, dtpred) * 100\n",
        "    print('Accuracy for this fold:', fold_accuracy)\n",
        "    total_accuracy += fold_accuracy\n",
        "    print(\"Confusion Matrix for Fold:\")\n",
        "    print(cm)\n",
        "\n",
        "dtaccuracy = total_accuracy / k\n",
        "print(\"Mean Accuracy =\", dtaccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIcGoPcWThKv",
        "outputId": "943681d8-d83f-4f7b-ce1c-fb10ec4c88aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for this fold: 76.66666666666667\n",
            "Confusion Matrix for Fold:\n",
            "[[11  3]\n",
            " [ 4 12]]\n",
            "Accuracy for this fold: 83.33333333333334\n",
            "Confusion Matrix for Fold:\n",
            "[[19  2]\n",
            " [ 3  6]]\n",
            "Accuracy for this fold: 86.66666666666667\n",
            "Confusion Matrix for Fold:\n",
            "[[21  2]\n",
            " [ 2  5]]\n",
            "Accuracy for this fold: 66.66666666666666\n",
            "Confusion Matrix for Fold:\n",
            "[[17  6]\n",
            " [ 4  3]]\n",
            "Accuracy for this fold: 89.65517241379311\n",
            "Confusion Matrix for Fold:\n",
            "[[18  1]\n",
            " [ 2  8]]\n",
            "Accuracy for this fold: 65.51724137931035\n",
            "Confusion Matrix for Fold:\n",
            "[[ 8  4]\n",
            " [ 6 11]]\n",
            "Accuracy for this fold: 93.10344827586206\n",
            "Confusion Matrix for Fold:\n",
            "[[20  0]\n",
            " [ 2  7]]\n",
            "Accuracy for this fold: 68.96551724137932\n",
            "Confusion Matrix for Fold:\n",
            "[[14  2]\n",
            " [ 7  6]]\n",
            "Accuracy for this fold: 68.96551724137932\n",
            "Confusion Matrix for Fold:\n",
            "[[15  5]\n",
            " [ 4  5]]\n",
            "Accuracy for this fold: 82.75862068965517\n",
            "Confusion Matrix for Fold:\n",
            "[[18  2]\n",
            " [ 3  6]]\n",
            "Mean Accuracy = 78.22988505747128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GAUSSIAN NB**"
      ],
      "metadata": {
        "id": "NcEOEo0sLhIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GaussianNB\n",
        "\n",
        "m5 = 'gaussian nb'\n",
        "k = 10\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=23)\n",
        "\n",
        "total_accuracy = 0\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    nb = GaussianNB()\n",
        "    nb.fit(X_train_fold,y_train_fold)\n",
        "    nbpred = nb.predict(X_test_fold)\n",
        "    cm = confusion_matrix(y_test_fold, nbpred)\n",
        "    fold_accuracy = accuracy_score(y_test_fold, nbpred) * 100\n",
        "    print('Accuracy for this fold:', fold_accuracy)\n",
        "    total_accuracy += fold_accuracy\n",
        "    print(\"Confusion Matrix for Fold:\")\n",
        "    print(cm)\n",
        "\n",
        "nbaccuracy = total_accuracy / k\n",
        "print(\"Mean Accuracy =\", nbaccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mUre3E9Ti_y",
        "outputId": "c581fcad-5ced-4b1b-85b5-800852aa482a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for this fold: 70.0\n",
            "Confusion Matrix for Fold:\n",
            "[[10  4]\n",
            " [ 5 11]]\n",
            "Accuracy for this fold: 86.66666666666667\n",
            "Confusion Matrix for Fold:\n",
            "[[18  3]\n",
            " [ 1  8]]\n",
            "Accuracy for this fold: 93.33333333333333\n",
            "Confusion Matrix for Fold:\n",
            "[[22  1]\n",
            " [ 1  6]]\n",
            "Accuracy for this fold: 70.0\n",
            "Confusion Matrix for Fold:\n",
            "[[16  7]\n",
            " [ 2  5]]\n",
            "Accuracy for this fold: 86.20689655172413\n",
            "Confusion Matrix for Fold:\n",
            "[[17  2]\n",
            " [ 2  8]]\n",
            "Accuracy for this fold: 82.75862068965517\n",
            "Confusion Matrix for Fold:\n",
            "[[ 9  3]\n",
            " [ 2 15]]\n",
            "Accuracy for this fold: 93.10344827586206\n",
            "Confusion Matrix for Fold:\n",
            "[[20  0]\n",
            " [ 2  7]]\n",
            "Accuracy for this fold: 82.75862068965517\n",
            "Confusion Matrix for Fold:\n",
            "[[15  1]\n",
            " [ 4  9]]\n",
            "Accuracy for this fold: 72.41379310344827\n",
            "Confusion Matrix for Fold:\n",
            "[[16  4]\n",
            " [ 4  5]]\n",
            "Accuracy for this fold: 82.75862068965517\n",
            "Confusion Matrix for Fold:\n",
            "[[17  3]\n",
            " [ 2  7]]\n",
            "Mean Accuracy = 82.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QDA**"
      ],
      "metadata": {
        "id": "Z_bbi2FbLpJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "m6 = 'qda classifier'\n",
        "k = 10\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=23)\n",
        "\n",
        "total_accuracy = 0\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    qda = QuadraticDiscriminantAnalysis()\n",
        "    qda.fit(X_train_fold, y_train_fold)\n",
        "    qdapred = qda.predict(X_test_fold)\n",
        "    cm = confusion_matrix(y_test_fold, qdapred)\n",
        "    fold_accuracy = accuracy_score(y_test_fold, qdapred) * 100\n",
        "    print('Accuracy for this fold:', fold_accuracy)\n",
        "    total_accuracy += fold_accuracy\n",
        "    print(\"Confusion Matrix for Fold:\")\n",
        "    print(cm)\n",
        "\n",
        "qdaaccuracy = total_accuracy / k\n",
        "print(\"Mean Accuracy =\", qdaaccuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NthYj97wTlf4",
        "outputId": "fb60053a-7243-413e-f367-992aee0aebe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for this fold: 46.666666666666664\n",
            "Confusion Matrix for Fold:\n",
            "[[14  0]\n",
            " [16  0]]\n",
            "Accuracy for this fold: 70.0\n",
            "Confusion Matrix for Fold:\n",
            "[[21  0]\n",
            " [ 9  0]]\n",
            "Accuracy for this fold: 76.66666666666667\n",
            "Confusion Matrix for Fold:\n",
            "[[23  0]\n",
            " [ 7  0]]\n",
            "Accuracy for this fold: 76.66666666666667\n",
            "Confusion Matrix for Fold:\n",
            "[[23  0]\n",
            " [ 7  0]]\n",
            "Accuracy for this fold: 65.51724137931035\n",
            "Confusion Matrix for Fold:\n",
            "[[19  0]\n",
            " [10  0]]\n",
            "Accuracy for this fold: 41.37931034482759\n",
            "Confusion Matrix for Fold:\n",
            "[[12  0]\n",
            " [17  0]]\n",
            "Accuracy for this fold: 68.96551724137932\n",
            "Confusion Matrix for Fold:\n",
            "[[20  0]\n",
            " [ 9  0]]\n",
            "Accuracy for this fold: 55.172413793103445\n",
            "Confusion Matrix for Fold:\n",
            "[[16  0]\n",
            " [13  0]]\n",
            "Accuracy for this fold: 68.96551724137932\n",
            "Confusion Matrix for Fold:\n",
            "[[20  0]\n",
            " [ 9  0]]\n",
            "Accuracy for this fold: 68.96551724137932\n",
            "Confusion Matrix for Fold:\n",
            "[[20  0]\n",
            " [ 9  0]]\n",
            "Mean Accuracy = 63.89655172413793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ENSEMBLING - BAGGING - RANDOM FOREST**"
      ],
      "metadata": {
        "id": "Yst7SW9ZLwB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "m7 = 'rf classifier'\n",
        "k = 10  # Number of folds\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=23)\n",
        "\n",
        "total_accuracy = 0\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    rf = RandomForestClassifier(n_estimators=5, random_state=2,max_depth=5)\n",
        "    rf.fit(X_train_fold, y_train_fold)\n",
        "    rfpred = rf.predict(X_test_fold)\n",
        "    cm = confusion_matrix(y_test_fold, rfpred)\n",
        "    fold_accuracy = accuracy_score(y_test_fold, rfpred) * 100\n",
        "    print('Accuracy for this fold:', fold_accuracy)\n",
        "    total_accuracy += fold_accuracy\n",
        "    print(\"Confusion Matrix for Fold:\")\n",
        "    print(cm)\n",
        "\n",
        "rfaccuracy = total_accuracy / k\n",
        "print(\"Mean Accuracy =\", rfaccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boMHQzLNTmSp",
        "outputId": "ac3e3b0f-89a5-4ec2-f461-36aaca530e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for this fold: 80.0\n",
            "Confusion Matrix for Fold:\n",
            "[[11  3]\n",
            " [ 3 13]]\n",
            "Accuracy for this fold: 80.0\n",
            "Confusion Matrix for Fold:\n",
            "[[19  2]\n",
            " [ 4  5]]\n",
            "Accuracy for this fold: 80.0\n",
            "Confusion Matrix for Fold:\n",
            "[[19  4]\n",
            " [ 2  5]]\n",
            "Accuracy for this fold: 66.66666666666666\n",
            "Confusion Matrix for Fold:\n",
            "[[17  6]\n",
            " [ 4  3]]\n",
            "Accuracy for this fold: 89.65517241379311\n",
            "Confusion Matrix for Fold:\n",
            "[[18  1]\n",
            " [ 2  8]]\n",
            "Accuracy for this fold: 86.20689655172413\n",
            "Confusion Matrix for Fold:\n",
            "[[10  2]\n",
            " [ 2 15]]\n",
            "Accuracy for this fold: 86.20689655172413\n",
            "Confusion Matrix for Fold:\n",
            "[[20  0]\n",
            " [ 4  5]]\n",
            "Accuracy for this fold: 82.75862068965517\n",
            "Confusion Matrix for Fold:\n",
            "[[16  0]\n",
            " [ 5  8]]\n",
            "Accuracy for this fold: 65.51724137931035\n",
            "Confusion Matrix for Fold:\n",
            "[[15  5]\n",
            " [ 5  4]]\n",
            "Accuracy for this fold: 86.20689655172413\n",
            "Confusion Matrix for Fold:\n",
            "[[19  1]\n",
            " [ 3  6]]\n",
            "Mean Accuracy = 80.32183908045977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ADABOOST - ENSEMBLING - BOOSTING**"
      ],
      "metadata": {
        "id": "3Uzn2lwGL6Pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m8 = 'adaboost classifier'\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "k = 10  # Number of folds\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=23)\n",
        "\n",
        "total_accuracy = 0\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    base_classifier = DecisionTreeClassifier(max_depth=6)\n",
        "    adaboost_classifier = AdaBoostClassifier(base_classifier, n_estimators=20, random_state=23)\n",
        "    adaboost_classifier.fit(X_train_fold, y_train_fold)\n",
        "    boostpred = adaboost_classifier.predict(X_test_fold)\n",
        "    cm = confusion_matrix(y_test_fold, boostpred)\n",
        "    fold_accuracy = accuracy_score(y_test_fold, boostpred) * 100\n",
        "    print('Accuracy for this fold:', fold_accuracy)\n",
        "    total_accuracy += fold_accuracy\n",
        "    print(\"Confusion Matrix for Fold:\")\n",
        "    print(cm)\n",
        "\n",
        "boostaccuracy = total_accuracy / k\n",
        "print(\"Mean Accuracy =\", boostaccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etP6DzSRTnKz",
        "outputId": "a2983a99-29a9-4c0b-c94c-7c7dddd499fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for this fold: 66.66666666666666\n",
            "Confusion Matrix for Fold:\n",
            "[[ 9  5]\n",
            " [ 5 11]]\n",
            "Accuracy for this fold: 83.33333333333334\n",
            "Confusion Matrix for Fold:\n",
            "[[18  3]\n",
            " [ 2  7]]\n",
            "Accuracy for this fold: 86.66666666666667\n",
            "Confusion Matrix for Fold:\n",
            "[[21  2]\n",
            " [ 2  5]]\n",
            "Accuracy for this fold: 63.33333333333333\n",
            "Confusion Matrix for Fold:\n",
            "[[17  6]\n",
            " [ 5  2]]\n",
            "Accuracy for this fold: 93.10344827586206\n",
            "Confusion Matrix for Fold:\n",
            "[[18  1]\n",
            " [ 1  9]]\n",
            "Accuracy for this fold: 79.3103448275862\n",
            "Confusion Matrix for Fold:\n",
            "[[ 9  3]\n",
            " [ 3 14]]\n",
            "Accuracy for this fold: 89.65517241379311\n",
            "Confusion Matrix for Fold:\n",
            "[[19  1]\n",
            " [ 2  7]]\n",
            "Accuracy for this fold: 79.3103448275862\n",
            "Confusion Matrix for Fold:\n",
            "[[15  1]\n",
            " [ 5  8]]\n",
            "Accuracy for this fold: 65.51724137931035\n",
            "Confusion Matrix for Fold:\n",
            "[[15  5]\n",
            " [ 5  4]]\n",
            "Accuracy for this fold: 79.3103448275862\n",
            "Confusion Matrix for Fold:\n",
            "[[16  4]\n",
            " [ 2  7]]\n",
            "Mean Accuracy = 78.62068965517241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRprKpkMQ0g6",
        "outputId": "d1ea1882-a249-4f3f-f4fd-813e7e88e31c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.3/612.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.22.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROPOSED DEEP LEARNING MODEL**"
      ],
      "metadata": {
        "id": "HyxltfFbMsnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Deep Learning Model\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "input_layer = Input(shape=(X_train.shape[1],))\n",
        "d1 = Dense(units=100, activation='relu')(input_layer)\n",
        "d2 = Dense(units=100, activation='relu')(d1)\n",
        "d3 = Dense(units=100, activation='relu')(d2)\n",
        "d4 = Dense(units=100, activation='relu')(d3)\n",
        "d5 = Dense(units=100, activation='relu')(d4)\n",
        "d6 = Dense(units=100, activation='relu')(d5)\n",
        "d7 = Dense(units=100, activation='relu')(d6)\n",
        "d8 = Dense(units=100, activation='relu')(d7)\n",
        "d9 = Dense(units=100, activation='relu')(d8)\n",
        "output_layer = Dense(units=1, activation='sigmoid')(d9)\n",
        "\n",
        "deepmodel = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model with metrics and optimizer\n",
        "deepmodel.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.Recall(name=\"Sensitivity\"),\n",
        "             tf.keras.metrics.SpecificityAtSensitivity(0.5, name=\"Specificity\"),\n",
        "             tfa.metrics.F1Score(num_classes=1, threshold=0.5)],\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "deepmodel.fit(x=X_train, y=y_train, batch_size=2, epochs=120)\n",
        "\n",
        "test_loss, test_accuracy, sensitivity, specificity, f1_score = deepmodel.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Sensitivity (Recall): {sensitivity:.2f}\")\n",
        "print(f\"Specificity (Precision): {specificity:.2f}\")\n",
        "print(\"f1Score=\" + str(list(map('{:.2f}%'.format,f1_score))))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ar9OpnitQ1C_",
        "outputId": "ee98c443-08fe-43a3-9406-fb0d55cbbca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "118/118 [==============================] - 4s 5ms/step - loss: 0.6912 - accuracy: 0.6085 - Sensitivity: 0.1765 - Specificity: 0.4133 - f1_score: 0.2459\n",
            "Epoch 2/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.6874 - accuracy: 0.6298 - Sensitivity: 0.0471 - Specificity: 0.4533 - f1_score: 0.0842\n",
            "Epoch 3/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.6426 - Sensitivity: 0.0118 - Specificity: 0.8133 - f1_score: 0.0233\n",
            "Epoch 4/120\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.6773 - accuracy: 0.6426 - Sensitivity: 0.0118 - Specificity: 0.8200 - f1_score: 0.0233\n",
            "Epoch 5/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.6699 - accuracy: 0.6426 - Sensitivity: 0.0118 - Specificity: 0.8533 - f1_score: 0.0233\n",
            "Epoch 6/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.6426 - Sensitivity: 0.0118 - Specificity: 0.9733 - f1_score: 0.0233\n",
            "Epoch 7/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.6463 - accuracy: 0.6426 - Sensitivity: 0.0118 - Specificity: 0.9600 - f1_score: 0.0233\n",
            "Epoch 8/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.6282 - accuracy: 0.6426 - Sensitivity: 0.0118 - Specificity: 0.9933 - f1_score: 0.0233    \n",
            "Epoch 9/120\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.6063 - accuracy: 0.6426 - Sensitivity: 0.0118 - Specificity: 0.9933 - f1_score: 0.0233\n",
            "Epoch 10/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.6638 - Sensitivity: 0.0706 - Specificity: 0.9933 - f1_score: 0.1319\n",
            "Epoch 11/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.7106 - Sensitivity: 0.2118 - Specificity: 0.9933 - f1_score: 0.3462\n",
            "Epoch 12/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7447 - Sensitivity: 0.3059 - Specificity: 0.9933 - f1_score: 0.4643\n",
            "Epoch 13/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7957 - Sensitivity: 0.4471 - Specificity: 0.9933 - f1_score: 0.6129\n",
            "Epoch 14/120\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.8085 - Sensitivity: 0.4824 - Specificity: 0.9933 - f1_score: 0.6457\n",
            "Epoch 15/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.8170 - Sensitivity: 0.5059 - Specificity: 0.9933 - f1_score: 0.6667\n",
            "Epoch 16/120\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.8340 - Sensitivity: 0.5765 - Specificity: 0.9933 - f1_score: 0.7153\n",
            "Epoch 17/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.8383 - Sensitivity: 0.5882 - Specificity: 0.9933 - f1_score: 0.7246\n",
            "Epoch 18/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.8426 - Sensitivity: 0.6235 - Specificity: 0.9933 - f1_score: 0.7413\n",
            "Epoch 19/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.8426 - Sensitivity: 0.6353 - Specificity: 0.9867 - f1_score: 0.7448\n",
            "Epoch 20/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.8468 - Sensitivity: 0.6588 - Specificity: 0.9867 - f1_score: 0.7568\n",
            "Epoch 21/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.8426 - Sensitivity: 0.6824 - Specificity: 0.9867 - f1_score: 0.7582\n",
            "Epoch 22/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8511 - Sensitivity: 0.7059 - Specificity: 0.9933 - f1_score: 0.7742\n",
            "Epoch 23/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.3994 - accuracy: 0.8553 - Sensitivity: 0.7176 - Specificity: 0.9867 - f1_score: 0.7821\n",
            "Epoch 24/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.3894 - accuracy: 0.8511 - Sensitivity: 0.7176 - Specificity: 0.9867 - f1_score: 0.7771\n",
            "Epoch 25/120\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3811 - accuracy: 0.8511 - Sensitivity: 0.7176 - Specificity: 0.9867 - f1_score: 0.7771\n",
            "Epoch 26/120\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3717 - accuracy: 0.8511 - Sensitivity: 0.7176 - Specificity: 0.9867 - f1_score: 0.7771\n",
            "Epoch 27/120\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3636 - accuracy: 0.8553 - Sensitivity: 0.7294 - Specificity: 0.9867 - f1_score: 0.7848\n",
            "Epoch 28/120\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3563 - accuracy: 0.8553 - Sensitivity: 0.7412 - Specificity: 0.9933 - f1_score: 0.7875\n",
            "Epoch 29/120\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.3496 - accuracy: 0.8638 - Sensitivity: 0.7294 - Specificity: 0.9867 - f1_score: 0.7949\n",
            "Epoch 30/120\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.3439 - accuracy: 0.8681 - Sensitivity: 0.7529 - Specificity: 0.9867 - f1_score: 0.8050\n",
            "Epoch 31/120\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3367 - accuracy: 0.8723 - Sensitivity: 0.7647 - Specificity: 0.9867 - f1_score: 0.8125\n",
            "Epoch 32/120\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3327 - accuracy: 0.8681 - Sensitivity: 0.7647 - Specificity: 0.9933 - f1_score: 0.8075\n",
            "Epoch 33/120\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.3262 - accuracy: 0.8766 - Sensitivity: 0.7647 - Specificity: 0.9933 - f1_score: 0.8176\n",
            "Epoch 34/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.3203 - accuracy: 0.8809 - Sensitivity: 0.7882 - Specificity: 0.9933 - f1_score: 0.8272\n",
            "Epoch 35/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.3169 - accuracy: 0.8851 - Sensitivity: 0.7882 - Specificity: 0.9933 - f1_score: 0.8323\n",
            "Epoch 36/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.3125 - accuracy: 0.8851 - Sensitivity: 0.7882 - Specificity: 0.9933 - f1_score: 0.8323\n",
            "Epoch 37/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.3080 - accuracy: 0.8851 - Sensitivity: 0.7882 - Specificity: 0.9933 - f1_score: 0.8323\n",
            "Epoch 38/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.3040 - accuracy: 0.8894 - Sensitivity: 0.8000 - Specificity: 0.9933 - f1_score: 0.8395\n",
            "Epoch 39/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.3005 - accuracy: 0.8894 - Sensitivity: 0.8000 - Specificity: 0.9933 - f1_score: 0.8395\n",
            "Epoch 40/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2968 - accuracy: 0.8936 - Sensitivity: 0.8118 - Specificity: 0.9933 - f1_score: 0.8466\n",
            "Epoch 41/120\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2942 - accuracy: 0.9064 - Sensitivity: 0.8235 - Specificity: 0.9933 - f1_score: 0.8642\n",
            "Epoch 42/120\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2900 - accuracy: 0.9021 - Sensitivity: 0.8000 - Specificity: 0.9933 - f1_score: 0.8553\n",
            "Epoch 43/120\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2867 - accuracy: 0.9064 - Sensitivity: 0.8118 - Specificity: 0.9933 - f1_score: 0.8625\n",
            "Epoch 44/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2849 - accuracy: 0.9106 - Sensitivity: 0.8235 - Specificity: 0.9933 - f1_score: 0.8696\n",
            "Epoch 45/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2808 - accuracy: 0.9064 - Sensitivity: 0.8118 - Specificity: 0.9933 - f1_score: 0.8625\n",
            "Epoch 46/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2773 - accuracy: 0.9021 - Sensitivity: 0.8000 - Specificity: 0.9933 - f1_score: 0.8553\n",
            "Epoch 47/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2750 - accuracy: 0.9106 - Sensitivity: 0.8235 - Specificity: 0.9933 - f1_score: 0.8696\n",
            "Epoch 48/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2715 - accuracy: 0.9106 - Sensitivity: 0.8235 - Specificity: 0.9933 - f1_score: 0.8696\n",
            "Epoch 49/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2690 - accuracy: 0.9106 - Sensitivity: 0.8235 - Specificity: 0.9933 - f1_score: 0.8696\n",
            "Epoch 50/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2664 - accuracy: 0.9106 - Sensitivity: 0.8235 - Specificity: 0.9933 - f1_score: 0.8696\n",
            "Epoch 51/120\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2636 - accuracy: 0.9106 - Sensitivity: 0.8235 - Specificity: 0.9933 - f1_score: 0.8696\n",
            "Epoch 52/120\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2610 - accuracy: 0.9149 - Sensitivity: 0.8353 - Specificity: 0.9933 - f1_score: 0.8765\n",
            "Epoch 53/120\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2580 - accuracy: 0.9106 - Sensitivity: 0.8235 - Specificity: 0.9933 - f1_score: 0.8696\n",
            "Epoch 54/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2553 - accuracy: 0.9149 - Sensitivity: 0.8353 - Specificity: 0.9933 - f1_score: 0.8765\n",
            "Epoch 55/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2533 - accuracy: 0.9106 - Sensitivity: 0.8235 - Specificity: 0.9933 - f1_score: 0.8696\n",
            "Epoch 56/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.9149 - Sensitivity: 0.8353 - Specificity: 0.9933 - f1_score: 0.8765\n",
            "Epoch 57/120\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.2478 - accuracy: 0.9149 - Sensitivity: 0.8588 - Specificity: 0.9933 - f1_score: 0.8795\n",
            "Epoch 58/120\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.2455 - accuracy: 0.9149 - Sensitivity: 0.8235 - Specificity: 0.9933 - f1_score: 0.8750\n",
            "Epoch 59/120\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2433 - accuracy: 0.9191 - Sensitivity: 0.8353 - Specificity: 0.9933 - f1_score: 0.8820\n",
            "Epoch 60/120\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2412 - accuracy: 0.9191 - Sensitivity: 0.8471 - Specificity: 0.9933 - f1_score: 0.8834\n",
            "Epoch 61/120\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2401 - accuracy: 0.9149 - Sensitivity: 0.8353 - Specificity: 0.9933 - f1_score: 0.8765\n",
            "Epoch 62/120\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2358 - accuracy: 0.9277 - Sensitivity: 0.8706 - Specificity: 0.9933 - f1_score: 0.8970\n",
            "Epoch 63/120\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2327 - accuracy: 0.9277 - Sensitivity: 0.8824 - Specificity: 0.9933 - f1_score: 0.8982\n",
            "Epoch 64/120\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2311 - accuracy: 0.9234 - Sensitivity: 0.8588 - Specificity: 0.9933 - f1_score: 0.8902\n",
            "Epoch 65/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2284 - accuracy: 0.9277 - Sensitivity: 0.8706 - Specificity: 0.9933 - f1_score: 0.8970\n",
            "Epoch 66/120\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2260 - accuracy: 0.9277 - Sensitivity: 0.8706 - Specificity: 0.9933 - f1_score: 0.8970\n",
            "Epoch 67/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2240 - accuracy: 0.9319 - Sensitivity: 0.8588 - Specificity: 0.9933 - f1_score: 0.9012\n",
            "Epoch 68/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2209 - accuracy: 0.9319 - Sensitivity: 0.8824 - Specificity: 0.9933 - f1_score: 0.9036\n",
            "Epoch 69/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2192 - accuracy: 0.9277 - Sensitivity: 0.8706 - Specificity: 0.9933 - f1_score: 0.8970\n",
            "Epoch 70/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2168 - accuracy: 0.9277 - Sensitivity: 0.8588 - Specificity: 0.9933 - f1_score: 0.8957\n",
            "Epoch 71/120\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2141 - accuracy: 0.9319 - Sensitivity: 0.8824 - Specificity: 0.9933 - f1_score: 0.9036\n",
            "Epoch 72/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2131 - accuracy: 0.9404 - Sensitivity: 0.8941 - Specificity: 0.9933 - f1_score: 0.9157\n",
            "Epoch 73/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9362 - Sensitivity: 0.8824 - Specificity: 0.9933 - f1_score: 0.9091\n",
            "Epoch 74/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2071 - accuracy: 0.9404 - Sensitivity: 0.8941 - Specificity: 0.9933 - f1_score: 0.9157\n",
            "Epoch 75/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2046 - accuracy: 0.9404 - Sensitivity: 0.8941 - Specificity: 0.9933 - f1_score: 0.9157\n",
            "Epoch 76/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2033 - accuracy: 0.9362 - Sensitivity: 0.8824 - Specificity: 0.9933 - f1_score: 0.9091\n",
            "Epoch 77/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2005 - accuracy: 0.9404 - Sensitivity: 0.8941 - Specificity: 0.9933 - f1_score: 0.9157\n",
            "Epoch 78/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1985 - accuracy: 0.9404 - Sensitivity: 0.8941 - Specificity: 0.9933 - f1_score: 0.9157\n",
            "Epoch 79/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1959 - accuracy: 0.9404 - Sensitivity: 0.8941 - Specificity: 0.9933 - f1_score: 0.9157\n",
            "Epoch 80/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1942 - accuracy: 0.9404 - Sensitivity: 0.8941 - Specificity: 0.9933 - f1_score: 0.9157\n",
            "Epoch 81/120\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.1917 - accuracy: 0.9404 - Sensitivity: 0.8941 - Specificity: 0.9933 - f1_score: 0.9157\n",
            "Epoch 82/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1900 - accuracy: 0.9404 - Sensitivity: 0.8941 - Specificity: 0.9933 - f1_score: 0.9157\n",
            "Epoch 83/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1878 - accuracy: 0.9404 - Sensitivity: 0.8941 - Specificity: 0.9933 - f1_score: 0.9157\n",
            "Epoch 84/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1859 - accuracy: 0.9489 - Sensitivity: 0.9176 - Specificity: 0.9933 - f1_score: 0.9286\n",
            "Epoch 85/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1833 - accuracy: 0.9404 - Sensitivity: 0.8941 - Specificity: 0.9933 - f1_score: 0.9157\n",
            "Epoch 86/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1813 - accuracy: 0.9447 - Sensitivity: 0.9059 - Specificity: 0.9933 - f1_score: 0.9222\n",
            "Epoch 87/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1788 - accuracy: 0.9489 - Sensitivity: 0.9176 - Specificity: 0.9933 - f1_score: 0.9286\n",
            "Epoch 88/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1778 - accuracy: 0.9447 - Sensitivity: 0.9059 - Specificity: 0.9933 - f1_score: 0.9222\n",
            "Epoch 89/120\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.1746 - accuracy: 0.9489 - Sensitivity: 0.9176 - Specificity: 0.9933 - f1_score: 0.9286\n",
            "Epoch 90/120\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.1729 - accuracy: 0.9489 - Sensitivity: 0.9176 - Specificity: 0.9933 - f1_score: 0.9286\n",
            "Epoch 91/120\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.1702 - accuracy: 0.9489 - Sensitivity: 0.9176 - Specificity: 0.9933 - f1_score: 0.9286\n",
            "Epoch 92/120\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.1683 - accuracy: 0.9489 - Sensitivity: 0.9176 - Specificity: 0.9933 - f1_score: 0.9286\n",
            "Epoch 93/120\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.1665 - accuracy: 0.9532 - Sensitivity: 0.9176 - Specificity: 0.9933 - f1_score: 0.9341\n",
            "Epoch 94/120\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.1641 - accuracy: 0.9447 - Sensitivity: 0.8941 - Specificity: 0.9933 - f1_score: 0.9212\n",
            "Epoch 95/120\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.1626 - accuracy: 0.9489 - Sensitivity: 0.9176 - Specificity: 0.9933 - f1_score: 0.9286\n",
            "Epoch 96/120\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.1593 - accuracy: 0.9574 - Sensitivity: 0.9294 - Specificity: 0.9933 - f1_score: 0.9405\n",
            "Epoch 97/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1575 - accuracy: 0.9617 - Sensitivity: 0.9294 - Specificity: 0.9933 - f1_score: 0.9461\n",
            "Epoch 98/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1544 - accuracy: 0.9617 - Sensitivity: 0.9294 - Specificity: 0.9933 - f1_score: 0.9461\n",
            "Epoch 99/120\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.1528 - accuracy: 0.9617 - Sensitivity: 0.9294 - Specificity: 0.9933 - f1_score: 0.9461\n",
            "Epoch 100/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1510 - accuracy: 0.9574 - Sensitivity: 0.9176 - Specificity: 0.9933 - f1_score: 0.9398\n",
            "Epoch 101/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9617 - Sensitivity: 0.9294 - Specificity: 0.9933 - f1_score: 0.9461\n",
            "Epoch 102/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1465 - accuracy: 0.9574 - Sensitivity: 0.9294 - Specificity: 0.9933 - f1_score: 0.9405\n",
            "Epoch 103/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9617 - Sensitivity: 0.9294 - Specificity: 0.9933 - f1_score: 0.9461\n",
            "Epoch 104/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1419 - accuracy: 0.9660 - Sensitivity: 0.9412 - Specificity: 0.9933 - f1_score: 0.9524\n",
            "Epoch 105/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1394 - accuracy: 0.9617 - Sensitivity: 0.9294 - Specificity: 0.9933 - f1_score: 0.9461\n",
            "Epoch 106/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1376 - accuracy: 0.9660 - Sensitivity: 0.9412 - Specificity: 0.9933 - f1_score: 0.9524\n",
            "Epoch 107/120\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.1352 - accuracy: 0.9660 - Sensitivity: 0.9412 - Specificity: 0.9933 - f1_score: 0.9524\n",
            "Epoch 108/120\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.1328 - accuracy: 0.9660 - Sensitivity: 0.9412 - Specificity: 0.9933 - f1_score: 0.9524\n",
            "Epoch 109/120\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.1309 - accuracy: 0.9660 - Sensitivity: 0.9412 - Specificity: 0.9933 - f1_score: 0.9524\n",
            "Epoch 110/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1284 - accuracy: 0.9660 - Sensitivity: 0.9412 - Specificity: 0.9933 - f1_score: 0.9524\n",
            "Epoch 111/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1262 - accuracy: 0.9660 - Sensitivity: 0.9412 - Specificity: 0.9933 - f1_score: 0.9524\n",
            "Epoch 112/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1237 - accuracy: 0.9660 - Sensitivity: 0.9412 - Specificity: 0.9933 - f1_score: 0.9524\n",
            "Epoch 113/120\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.1223 - accuracy: 0.9660 - Sensitivity: 0.9412 - Specificity: 0.9933 - f1_score: 0.9524\n",
            "Epoch 114/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1208 - accuracy: 0.9702 - Sensitivity: 0.9529 - Specificity: 0.9933 - f1_score: 0.9586\n",
            "Epoch 115/120\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.1181 - accuracy: 0.9702 - Sensitivity: 0.9529 - Specificity: 0.9933 - f1_score: 0.9586\n",
            "Epoch 116/120\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.1155 - accuracy: 0.9745 - Sensitivity: 0.9647 - Specificity: 0.9933 - f1_score: 0.9647\n",
            "Epoch 117/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1144 - accuracy: 0.9745 - Sensitivity: 0.9647 - Specificity: 0.9933 - f1_score: 0.9647\n",
            "Epoch 118/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1120 - accuracy: 0.9745 - Sensitivity: 0.9647 - Specificity: 0.9933 - f1_score: 0.9647\n",
            "Epoch 119/120\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1107 - accuracy: 0.9702 - Sensitivity: 0.9529 - Specificity: 0.9933 - f1_score: 0.9586\n",
            "Epoch 120/120\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.1081 - accuracy: 0.9745 - Sensitivity: 0.9647 - Specificity: 0.9933 - f1_score: 0.9647\n",
            "2/2 [==============================] - 1s 16ms/step - loss: 0.4909 - accuracy: 0.7797 - Sensitivity: 0.7619 - Specificity: 0.9737 - f1_score: 0.7111\n",
            "Test Accuracy: 77.97%\n",
            "Sensitivity (Recall): 0.76\n",
            "Specificity (Precision): 0.97\n",
            "f1Score=['0.71%']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_names = ['Logistic Regression', 'Naive Bayes', 'Random Forest','adaboost classifier', 'K-Nearest Neighbour', 'Decision Tree', 'Support Vector Machine','Deep Learning Model ']\n",
        "accuracy_scores = [lraccuracy,nbaccuracy,rfaccuracy,boostaccuracy,knnaccuracy,dtaccuracy,svmaccuracy,test_accuracy*100]\n",
        "model_ev = pd.DataFrame({'Model': model_names, 'Accuracy': accuracy_scores})\n",
        "model_ev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q7naZotWepp",
        "outputId": "a81658ad-e3a7-4b8c-e21a-fa6b647cb00b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Model   Accuracy\n",
              "0     Logistic Regression  81.988506\n",
              "1             Naive Bayes  82.000000\n",
              "2           Random Forest  80.321839\n",
              "3     adaboost classifier  78.620690\n",
              "4     K-Nearest Neighbour  63.275862\n",
              "5           Decision Tree  78.229885\n",
              "6  Support Vector Machine  82.344828\n",
              "7    Deep Learning Model   77.966100"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2280079-8ef9-4c3e-8743-1dd3143f048e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>81.988506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>82.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>80.321839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>adaboost classifier</td>\n",
              "      <td>78.620690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>K-Nearest Neighbour</td>\n",
              "      <td>63.275862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>78.229885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Support Vector Machine</td>\n",
              "      <td>82.344828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Deep Learning Model</td>\n",
              "      <td>77.966100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2280079-8ef9-4c3e-8743-1dd3143f048e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b2280079-8ef9-4c3e-8743-1dd3143f048e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b2280079-8ef9-4c3e-8743-1dd3143f048e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-010332cc-887a-49e3-afb7-ef0f42e401b3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-010332cc-887a-49e3-afb7-ef0f42e401b3')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-010332cc-887a-49e3-afb7-ef0f42e401b3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "colors = ['red', 'orange', 'yellow', 'green', 'blue', 'gold', 'orange', ]\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.title(\"Barchart Accuracy of Different ML Models\")\n",
        "plt.xlabel(\"Algorithms\")\n",
        "plt.ylabel(\"% Accuracy\")\n",
        "plt.bar(model_ev ['Model'], model_ev['Accuracy'], color = colors)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1DUCHqeWfvy",
        "outputId": "de26215e-4d4e-4ec8-ef7a-840cd133345f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}